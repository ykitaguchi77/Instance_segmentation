{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuA1rS4nxYhWwZmIbaGIaQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Instance_segmentation/blob/main/MPLD_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MPLD analysis**"
      ],
      "metadata": {
        "id": "h1DBeaeIsrIF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQwGfev4S5bq",
        "outputId": "41a96bf8-e3e0-4b9a-c6c4-4e1794c4efb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: gdrive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detect_model_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/models/295+cerebhq1-20000_yolo11l.pt\"\n",
        "seg_model_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/models/eyelid_caruncle_yolo11seg_1-139.pt\"\n",
        "obb_model_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/models/yolo11n_obb_1-295_1to139.pt\""
      ],
      "metadata": {
        "id": "7RJFGmsJTiLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_test_images/Control_adult/1000.jpg\""
      ],
      "metadata": {
        "id": "034O76ThU0IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics --q\n",
        "!pip install japanize-matplotlib --q\n",
        "import japanize_matplotlib # インポートするだけで日本語対応が改善されます"
      ],
      "metadata": {
        "collapsed": true,
        "id": "69ApZnGEbnFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b102a2d-b7f2-4968-e23d-5aa33487c0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Google Driveをマウント (Colabで実行する場合)\n",
        "# try:\n",
        "#     drive.mount('/content/drive')\n",
        "# except OSError as e:\n",
        "#     if \"already mounted\" in str(e).lower():\n",
        "#         print(\"Google Drive is already mounted.\")\n",
        "#     else:\n",
        "#         raise e\n",
        "\n",
        "# --- 1. パス設定 ---\n",
        "detect_model_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/models/295+cerebhq1-20000_yolo11l.pt\"\n",
        "# seg_model_path と obb_model_path はこのスクリプトでは使用しません\n",
        "# seg_model_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/models/eyelid_caruncle_yolo11seg_1-139.pt\"\n",
        "# obb_model_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/models/yolo11n_obb_1-295_1to139.pt\"\n",
        "image_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_test_images/退行性眼瞼下垂/1065-20150514-73-130021_f6728a8d37efcf237c38e21309bb4ec7535a838429b7448eddfcc2b1fcc17e68.jpg\"\n",
        "\n",
        "# --- 2. モデルのロード ---\n",
        "try:\n",
        "    detect_model = YOLO(detect_model_path)\n",
        "    print(f\"Detection model '{detect_model_path}' loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading detection model: {e}\")\n",
        "    # スクリプトの実行をここで停止するか、適切に処理\n",
        "    exit()\n",
        "\n",
        "# --- 3. 画像のロード ---\n",
        "try:\n",
        "    img_pil = Image.open(image_path).convert(\"RGB\")\n",
        "    img_cv_rgb = np.array(img_pil) # OpenCVで処理するためにNumpy配列 (RGB) に変換\n",
        "    original_img_height, original_img_width = img_cv_rgb.shape[:2]\n",
        "    print(f\"Image '{image_path}' loaded successfully. Dimensions: {original_img_width}x{original_img_height}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Image file not found at '{image_path}'\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading image: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- ★★★ クロップ前の元画像を表示 (追加箇所) ★★★ ---\n",
        "plt.figure(figsize=(8, 8)) # 表示サイズはお好みで調整してください\n",
        "plt.imshow(img_pil) # または plt.imshow(img_cv_rgb)\n",
        "plt.title(f\"Original Image: {os.path.basename(image_path)}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "print(f\"Original image '{os.path.basename(image_path)}' displayed.\")\n",
        "# --- ★★★ 追加箇所ここまで ★★★ ---\n",
        "\n",
        "# --- 4. 物体検出の実行 ---\n",
        "print(\"Running detection model...\")\n",
        "results = detect_model(img_pil, verbose=False) # verbose=Falseで検出ログを抑制\n",
        "print(\"Detection complete.\")\n",
        "\n",
        "# --- 5. BBoxの処理と画像の切り抜き ---\n",
        "cropped_images_pil = []\n",
        "\n",
        "if results and len(results) > 0 and results[0].boxes:\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy()  # バウンディングボックスをxyxy形式で取得\n",
        "    print(f\"Found {len(boxes)} bounding box(es).\")\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "        bbox_width = x2 - x1\n",
        "        bbox_height = y2 - y1\n",
        "        bbox_center_x = x1 + bbox_width / 2.0\n",
        "        bbox_center_y = y1 + bbox_height / 2.0\n",
        "\n",
        "        print(f\"\\nProcessing BBox {i+1}: [x1={x1}, y1={y1}, x2={x2}, y2={y2}]\")\n",
        "        print(f\"  Original BBox width: {bbox_width}, height: {bbox_height}, center: ({bbox_center_x:.2f}, {bbox_center_y:.2f})\")\n",
        "\n",
        "        # 横幅を25%ずつ水増し (元の1.5倍)\n",
        "        new_width = int(round(bbox_width * 1.5))\n",
        "        # 縦幅は新しい横幅と一致させる\n",
        "        new_height = new_width\n",
        "\n",
        "        print(f\"  Target new width: {new_width}, new height: {new_height}\")\n",
        "\n",
        "        # 切り抜き用の座標を計算 (中心を維持)\n",
        "        crop_x1 = int(round(bbox_center_x - new_width / 2.0))\n",
        "        crop_y1 = int(round(bbox_center_y - new_height / 2.0))\n",
        "        crop_x2 = crop_x1 + new_width\n",
        "        crop_y2 = crop_y1 + new_height\n",
        "\n",
        "        print(f\"  Calculated crop window: [x1'={crop_x1}, y1'={crop_y1}, x2'={crop_x2}, y2'={crop_y2}]\")\n",
        "\n",
        "        # パディング量の計算\n",
        "        pad_left = max(0, -crop_x1)\n",
        "        pad_top = max(0, -crop_y1)\n",
        "        pad_right = max(0, crop_x2 - original_img_width)\n",
        "        pad_bottom = max(0, crop_y2 - original_img_height)\n",
        "\n",
        "        print(f\"  Padding needed: top={pad_top}, bottom={pad_bottom}, left={pad_left}, right={pad_right}\")\n",
        "\n",
        "        # 実際に画像から切り取る範囲を調整 (画像範囲内に収める)\n",
        "        actual_crop_x1_img = crop_x1 + pad_left\n",
        "        actual_crop_y1_img = crop_y1 + pad_top\n",
        "        actual_crop_x2_img = crop_x2 - pad_right\n",
        "        actual_crop_y2_img = crop_y2 - pad_bottom\n",
        "\n",
        "        print(f\"  Actual crop from image: [x_start={actual_crop_x1_img}, y_start={actual_crop_y1_img}, x_end={actual_crop_x2_img}, y_end={actual_crop_y2_img}]\")\n",
        "\n",
        "        # 画像を切り抜く (Numpy配列スライス)\n",
        "        # スライスする前に、座標が画像の範囲内にあることを確認\n",
        "        actual_crop_x1_img = max(0, actual_crop_x1_img)\n",
        "        actual_crop_y1_img = max(0, actual_crop_y1_img)\n",
        "        actual_crop_x2_img = min(original_img_width, actual_crop_x2_img)\n",
        "        actual_crop_y2_img = min(original_img_height, actual_crop_y2_img)\n",
        "\n",
        "        if actual_crop_x1_img >= actual_crop_x2_img or actual_crop_y1_img >= actual_crop_y2_img:\n",
        "            print(f\"  Skipping BBox {i+1} due to invalid crop dimensions after clamping.\")\n",
        "            # 有効な切り抜き領域がない場合は、黒一色の画像を生成するか、スキップ\n",
        "            # ここでは、指定サイズの黒画像を生成\n",
        "            cropped_part = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            cropped_part_from_img = img_cv_rgb[actual_crop_y1_img:actual_crop_y2_img, actual_crop_x1_img:actual_crop_x2_img]\n",
        "            # パディングを適用\n",
        "            # cv2.copyMakeBorderのvalueはBGRだが、黒(0,0,0)なのでRGBでも同じ\n",
        "            cropped_part = cv2.copyMakeBorder(\n",
        "                cropped_part_from_img,\n",
        "                pad_top,\n",
        "                pad_bottom,\n",
        "                pad_left,\n",
        "                pad_right,\n",
        "                cv2.BORDER_CONSTANT,\n",
        "                value=[0, 0, 0]  # 黒でパディング\n",
        "            )\n",
        "\n",
        "        # 稀にパディング計算や丸め誤差で1pxずれることがある場合、リサイズで最終サイズを保証\n",
        "        if cropped_part.shape[0] != new_height or cropped_part.shape[1] != new_width:\n",
        "            print(f\"  Warning: Padded crop size ({cropped_part.shape[1]}x{cropped_part.shape[0]}) differs from target ({new_width}x{new_height}). Resizing.\")\n",
        "            cropped_part = cv2.resize(cropped_part, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "        cropped_images_pil.append(Image.fromarray(cropped_part)) # Pillow Imageとしてリストに追加\n",
        "        print(f\"  Cropped and padded image {i+1} generated. Final size: {cropped_part.shape[1]}x{cropped_part.shape[0]}\")\n",
        "\n",
        "else:\n",
        "    print(\"No objects detected or no bounding boxes found in the results.\")\n",
        "\n",
        "# --- 6. 切り抜いた画像の表示 ---\n",
        "if cropped_images_pil:\n",
        "    num_cropped = len(cropped_images_pil)\n",
        "    # 表示する画像の数に応じて subplot のレイアウトを調整\n",
        "    cols = min(num_cropped, 3) # 最大3列で表示\n",
        "    rows = (num_cropped + cols - 1) // cols # 必要な行数\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n",
        "    axes = np.array(axes).ravel() # axesを1次元配列に変換して扱いやすくする\n",
        "\n",
        "    for i, cropped_img_pil in enumerate(cropped_images_pil):\n",
        "        axes[i].imshow(cropped_img_pil)\n",
        "        axes[i].set_title(f\"Cropped Image {i+1}\")\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    # 余分な subplot を非表示にする\n",
        "    for j in range(num_cropped, len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(f\"\\nDisplayed {num_cropped} cropped image(s).\")\n",
        "elif not (results and len(results) > 0 and results[0].boxes):\n",
        "    pass # すでに \"No objects detected...\" のメッセージが表示されている\n",
        "else:\n",
        "    print(\"No valid bounding boxes were processed to generate cropped images.\")\n",
        "\n",
        "\n",
        "# --- 7. 追加モデルのロード ---\n",
        "seg_model_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/models/eyelid_caruncle_yolo11seg_1-139.pt\"\n",
        "obb_model_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/models/yolo11n_obb_1-295_1to139.pt\"\n",
        "\n",
        "print(\"\\n--- Loading additional models ---\")\n",
        "try:\n",
        "    seg_model = YOLO(seg_model_path)\n",
        "    print(f\"Segmentation model '{seg_model_path}' loaded successfully.\")\n",
        "    obb_model = YOLO(obb_model_path)\n",
        "    print(f\"OBB model '{obb_model_path}' loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading additional models: {e}\")\n",
        "    # エラーが発生した場合、以降の処理をスキップするかどうかを決定\n",
        "    # ここでは、エラーメッセージを表示して終了する代わりに、merged_images_pilが空のまま処理を進める\n",
        "    seg_model = None\n",
        "    obb_model = None\n",
        "\n",
        "\n",
        "# --- 8. 各切り抜き画像への推論と結果のマージ ---\n",
        "merged_images_pil = []\n",
        "\n",
        "if not cropped_images_pil:\n",
        "    print(\"No cropped images from the previous step to process.\")\n",
        "elif seg_model is None or obb_model is None:\n",
        "    print(\"One or more additional models failed to load. Skipping merge step.\")\n",
        "else:\n",
        "    print(f\"\\n--- Processing {len(cropped_images_pil)} cropped image(s) with segmentation and OBB models ---\")\n",
        "    for i, base_cropped_pil in enumerate(cropped_images_pil):\n",
        "        print(f\"  Processing cropped image {i+1}/{len(cropped_images_pil)}...\")\n",
        "\n",
        "        # 元の切り抜き画像 (Pillow RGB) をコピーして作業用にする\n",
        "        # 推論は元のクリーンな画像で行う\n",
        "        current_pil_image = base_cropped_pil.copy()\n",
        "        current_rgb_numpy = np.array(current_pil_image) # RGB NumPy array\n",
        "\n",
        "        # 1. セグメンテーション推論と描画\n",
        "        # plot()はBGRのNumPy配列を返す。入力imgはRGB/BGRのNumPy配列を受け付ける。\n",
        "        # ここでは、まずセグメンテーションの結果を元のRGB画像に描画する。\n",
        "        # plot()のimgに渡す配列はコピーする方が安全。\n",
        "        img_with_seg_bgr = None\n",
        "        try:\n",
        "            print(f\"    Running segmentation model on image {i+1} with retina_masks=True...\")\n",
        "            results_seg = seg_model(\n",
        "                current_pil_image,\n",
        "                verbose=False,\n",
        "                conf=0.35, # confはお好みで調整\n",
        "                retina_masks=True # ★ 高品質マスク生成オプションを追加\n",
        "            )\n",
        "            if results_seg and results_seg[0].masks is not None: # マスクが存在する場合のみ描画\n",
        "                img_with_seg_bgr = results_seg[0].plot(\n",
        "                    img=current_rgb_numpy.copy(), # 元のRGB画像に描画\n",
        "                    pil=False,                    # NumPy配列(BGR)で結果取得\n",
        "                    masks=True,                   # マスクを描画\n",
        "                    boxes=False,                  # セグメンテーションのBBoxは描画しない (任意)\n",
        "                    labels=True                   # ラベルを描画\n",
        "                )\n",
        "                print(f\"    Segmentation applied to image {i+1}.\")\n",
        "            else:\n",
        "                print(f\"    No segmentation masks found by seg_model for image {i+1}.\")\n",
        "                # マスクがない場合は、元の画像をBGRに変換したものを使用\n",
        "                img_with_seg_bgr = cv2.cvtColor(current_rgb_numpy.copy(), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error during segmentation on image {i+1}: {e}\")\n",
        "            # エラー発生時は、元の画像をBGRに変換したものを次のステップのベースとする\n",
        "            img_with_seg_bgr = cv2.cvtColor(current_rgb_numpy.copy(), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "\n",
        "        # 2. OBB推論と描画\n",
        "        # OBBモデルの推論は、元のクリーンな画像 (current_pil_image) で行う。\n",
        "        # 描画は、セグメンテーションが描画された画像 (img_with_seg_bgr) に対して行う。\n",
        "        final_img_np_bgr = None\n",
        "        try:\n",
        "            print(f\"    Running OBB model on image {i+1}...\")\n",
        "            results_obb = obb_model(current_pil_image, verbose=False, conf=0.35) # confはお好みで調整\n",
        "            if results_obb and hasattr(results_obb[0], 'obb') and results_obb[0].obb is not None: # OBBが存在する場合のみ描画\n",
        "                 # OBBの結果を、セグメンテーションが描画済みの画像 (img_with_seg_bgr) に重ねて描画\n",
        "                final_img_np_bgr = results_obb[0].plot(\n",
        "                    img=img_with_seg_bgr.copy(), # セグメンテーション描画済みのBGR画像\n",
        "                    pil=False,                 # NumPy配列(BGR)で結果取得\n",
        "                    masks=False,               # OBBモデルは通常マスク出力しない\n",
        "                    boxes=True,                # OBBを描画 (これがOBBを描画するはず)\n",
        "                    labels=True                # ラベルを描画\n",
        "                )\n",
        "                print(f\"    OBB applied to image {i+1}.\")\n",
        "            else:\n",
        "                print(f\"    No OBB detections found by obb_model for image {i+1}.\")\n",
        "                final_img_np_bgr = img_with_seg_bgr.copy() # OBBがない場合は直前の画像\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error during OBB detection on image {i+1}: {e}\")\n",
        "            # エラー発生時は、セグメンテーション描画後の画像を最終結果とする\n",
        "            final_img_np_bgr = img_with_seg_bgr.copy()\n",
        "\n",
        "        # 最終結果 (BGR NumPy array) をPillow Image (RGB) に変換してリストに追加\n",
        "        final_img_pil = Image.fromarray(cv2.cvtColor(final_img_np_bgr, cv2.COLOR_BGR2RGB))\n",
        "        merged_images_pil.append(final_img_pil)\n",
        "        print(f\"  Finished processing and merging for image {i+1}.\")\n",
        "\n",
        "# --- 9. マージされた画像の表示 ---\n",
        "if merged_images_pil:\n",
        "    print(f\"\\n--- Displaying {len(merged_images_pil)} merged image(s) ---\")\n",
        "    num_merged = len(merged_images_pil)\n",
        "    # 表示する画像の数に応じて subplot のレイアウトを調整\n",
        "    cols = min(num_merged, 3) # 最大3列で表示\n",
        "    rows = (num_merged + cols - 1) // cols # 必要な行数\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(7 * cols, 7 * rows)) # figsizeを少し調整\n",
        "    if num_merged == 1: # 画像が1枚の場合、axesはオブジェクトであり、配列ではない\n",
        "        axes = np.array([axes])\n",
        "    axes = axes.ravel() # axesを1次元配列に変換して扱いやすくする\n",
        "\n",
        "    for i, merged_img_pil in enumerate(merged_images_pil):\n",
        "        axes[i].imshow(merged_img_pil)\n",
        "        axes[i].set_title(f\"Merged Result {i+1}\")\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    # 余分な subplot があれば非表示にする\n",
        "    for j in range(num_merged, len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    if cropped_images_pil and (seg_model is not None and obb_model is not None):\n",
        "        print(\"No images were successfully merged. Check logs for errors.\")\n",
        "    # cropped_images_pilが空だった場合やモデルロード失敗のメッセージは既に表示されている"
      ],
      "metadata": {
        "id": "1j_hGq48a5Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0Jah8V-pvdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple MPLD analysis**"
      ],
      "metadata": {
        "id": "g4cyGTh_X0ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "# Colabで日本語フォントを使用するための準備 (事前にセルで実行推奨)\n",
        "# !pip install japanize-matplotlib\n",
        "import japanize_matplotlib # インポートするだけで日本語表示が改善されます\n",
        "\n",
        "# --- 1. パス設定 ---\n",
        "# !!!以下のパスはご自身の環境に合わせてください!!!\n",
        "drive_base_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/\" # Google Driveのベースパス例\n",
        "detect_model_path = os.path.join(drive_base_path, \"models/295+cerebhq1-20000_yolo11l.pt\")\n",
        "seg_model_path = os.path.join(drive_base_path, \"models/eyelid_caruncle_yolo11seg_1-139.pt\")\n",
        "obb_model_path = os.path.join(drive_base_path, \"models/yolo11n_obb_1-295_1to139.pt\")\n",
        "image_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_test_images/退行性眼瞼下垂/1065-20150514-73-130021_f6728a8d37efcf237c38e21309bb4ec7535a838429b7448eddfcc2b1fcc17e68.jpg\" # 解析したい画像へのパス\n",
        "\n",
        "# --- 定数定義 ---\n",
        "OBB_CLASS_PUPIL = 'Pupil'\n",
        "OBB_CLASS_IRIS = 'Iris'\n",
        "SEG_CLASS_EYELID = 'Eyelid'\n",
        "CORNEAL_DIAMETER_MM = 12.0\n",
        "RADIAL_ANGLES_DEG = [i * 15 for i in range(24)] # 0°から345°まで15°間隔\n",
        "\n",
        "# --- 出力ディレクトリ作成 ---\n",
        "output_dir = \"/content/mrmpd_results\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"結果は '{output_dir}' ディレクトリに保存されます。\")\n",
        "\n",
        "# --- ヘルパー関数: OBBデータ抽出 ---\n",
        "def get_obb_data_by_class_name(obb_results_obj, target_class_name, model_obb_names, img_idx_for_debug=\"N/A\"):\n",
        "    if obb_results_obj is None or not hasattr(obb_results_obj, 'obb') or obb_results_obj.obb is None or \\\n",
        "       not hasattr(obb_results_obj.obb, 'cls') or len(obb_results_obj.obb.cls) == 0:\n",
        "        return None\n",
        "    target_cls_indices = []\n",
        "    if isinstance(model_obb_names, dict): # モデルのnames属性が辞書の場合\n",
        "        for cls_id, name in model_obb_names.items():\n",
        "            if name == target_class_name:\n",
        "                target_cls_indices.append(int(cls_id)) # クラスIDは整数\n",
        "    elif isinstance(model_obb_names, list): # モデルのnames属性がリストの場合\n",
        "        for cls_id, name in enumerate(model_obb_names):\n",
        "            if name == target_class_name:\n",
        "                target_cls_indices.append(cls_id)\n",
        "    else: # 不明な形式\n",
        "        print(f\"警告 (画像 {img_idx_for_debug}, get_obb_data): model_obb_names の形式が不明です: {type(model_obb_names)}\")\n",
        "        return None\n",
        "\n",
        "    if not target_cls_indices: return None\n",
        "    best_obb_data = None; highest_conf = -1.0\n",
        "    if not hasattr(obb_results_obj.obb, 'conf') or not hasattr(obb_results_obj.obb, 'xywhr'): return None\n",
        "\n",
        "    detected_classes = obb_results_obj.obb.cls.cpu().numpy().astype(int)\n",
        "    confidences = obb_results_obj.obb.conf.cpu().numpy()\n",
        "    xywhr_data = obb_results_obj.obb.xywhr.cpu().numpy()\n",
        "\n",
        "    found_instances = 0\n",
        "    for i in range(len(detected_classes)):\n",
        "        if detected_classes[i] in target_cls_indices:\n",
        "            found_instances +=1; current_conf = confidences[i]\n",
        "            if current_conf > highest_conf:\n",
        "                highest_conf = current_conf\n",
        "                best_obb_data = {\n",
        "                    \"center_x\": xywhr_data[i][0], \"center_y\": xywhr_data[i][1],\n",
        "                    \"width\": xywhr_data[i][2], \"height\": xywhr_data[i][3],\n",
        "                    \"angle_rad\": xywhr_data[i][4], \"confidence\": current_conf\n",
        "                }\n",
        "    return best_obb_data if found_instances > 0 and best_obb_data is not None else None\n",
        "\n",
        "# --- ヘルパー関数: セグメンテーションマスク抽出 ---\n",
        "def get_mask_by_class_name(seg_results_obj, target_class_name, model_seg_names, target_shape_hw, img_idx_for_debug=\"N/A\"):\n",
        "    if seg_results_obj.masks is None: return None\n",
        "    if not hasattr(seg_results_obj.masks, 'data') or seg_results_obj.masks.data is None: return None\n",
        "    if seg_results_obj.boxes is None: return None # boxes属性もチェック\n",
        "\n",
        "    target_cls_indices = []\n",
        "    if isinstance(model_seg_names, dict): # モデルのnames属性が辞書の場合\n",
        "        for cls_id, name in model_seg_names.items():\n",
        "            if name == target_class_name: target_cls_indices.append(int(cls_id))\n",
        "    elif isinstance(model_seg_names, list): # モデルのnames属性がリストの場合\n",
        "        for cls_id, name in enumerate(model_seg_names):\n",
        "            if name == target_class_name: target_cls_indices.append(cls_id)\n",
        "    else:\n",
        "        print(f\"警告 (画像 {img_idx_for_debug}, get_mask): model_seg_names の形式が不明です: {type(model_seg_names)}\")\n",
        "        return None\n",
        "\n",
        "    if not target_cls_indices: return None\n",
        "\n",
        "    relevant_masks_data = []\n",
        "    all_detected_cls_indices = seg_results_obj.boxes.cls.cpu().numpy().astype(int)\n",
        "    raw_masks_tensor = seg_results_obj.masks.data # (N, H_proto, W_proto)\n",
        "\n",
        "    if raw_masks_tensor is None or len(raw_masks_tensor) == 0: return None\n",
        "\n",
        "    # boxesの数とmasks.dataの最初の次元が一致するか確認\n",
        "    if len(all_detected_cls_indices) != raw_masks_tensor.shape[0]:\n",
        "        print(f\"警告 (画像 {img_idx_for_debug}, get_mask): ボックス数 ({len(all_detected_cls_indices)}) とマスク数 ({raw_masks_tensor.shape[0]}) が一致しません。\")\n",
        "        # 処理を続行するか、ここでエラーとするか検討。短い方でループするのが安全\n",
        "        num_to_iterate = min(len(all_detected_cls_indices), raw_masks_tensor.shape[0])\n",
        "    else:\n",
        "        num_to_iterate = len(all_detected_cls_indices)\n",
        "\n",
        "    for i in range(num_to_iterate):\n",
        "        current_model_cls_idx = all_detected_cls_indices[i]\n",
        "        if current_model_cls_idx in target_cls_indices:\n",
        "            try:\n",
        "                mask_proto = raw_masks_tensor[i]; # (H_proto, W_proto)\n",
        "                mask_proto_tensor = mask_proto.unsqueeze(0).unsqueeze(0) # (1,1,H_proto,W_proto)\n",
        "\n",
        "                if mask_proto_tensor.shape[2:] == target_shape_hw: # 既にターゲットサイズの場合\n",
        "                    upsampled_mask_tensor = mask_proto_tensor.squeeze()\n",
        "                else: # アップサンプリング\n",
        "                    upsampled_mask_tensor = torch.nn.functional.interpolate(\n",
        "                        mask_proto_tensor, size=target_shape_hw, mode='bilinear', align_corners=False\n",
        "                    ).squeeze() # (target_H, target_W)\n",
        "\n",
        "                mask_np = upsampled_mask_tensor.cpu().numpy()\n",
        "                mask_np_binary = (mask_np > 0.5).astype(np.uint8) * 255\n",
        "                contours, _ = cv2.findContours(mask_np_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                area = sum(cv2.contourArea(c) for c in contours) if contours else 0\n",
        "                if area > 0: relevant_masks_data.append({'mask': mask_np_binary, 'area': area})\n",
        "            except Exception as e:\n",
        "                print(f\"エラー (画像 {img_idx_for_debug}, get_mask): '{target_class_name}' のインスタンス {i} のマスク処理中に例外: {e}\")\n",
        "                continue # このマスクの処理はスキップ\n",
        "\n",
        "    if not relevant_masks_data: return None\n",
        "    largest_mask_data = max(relevant_masks_data, key=lambda x: x['area'])\n",
        "    return largest_mask_data['mask']\n",
        "\n",
        "# --- ヘルパー関数: 角度の正規化と範囲チェック ---\n",
        "def normalize_angle_deg(angle_deg):\n",
        "    angle = angle_deg % 360\n",
        "    return angle if angle >= 0 else angle + 360\n",
        "\n",
        "def is_angle_in_upper_lid_range(angle_deg_to_check, inner_end_deg, outer_end_deg):\n",
        "    \"\"\"指定された角度が、定義された上まぶたの角度範囲内（内端から反時計回りに外端まで）にあるか判定\"\"\"\n",
        "    angle = normalize_angle_deg(angle_deg_to_check)\n",
        "    start = normalize_angle_deg(inner_end_deg) # 例: 350 (ほぼ0に近い右)\n",
        "    end = normalize_angle_deg(outer_end_deg)   # 例: 190 (左下)\n",
        "\n",
        "    if start <= end: # 0度をまたがない範囲 (例: start=10, end=170) -> 上まぶたが通常の半円に近い場合\n",
        "        return start <= angle <= end\n",
        "    else: # 0度をまたぐ範囲 (例: start=350 (右側), end=20 (右側)) -> 上まぶたが0度をまたいでいる場合\n",
        "        return angle >= start or angle <= end\n",
        "\n",
        "# --- ヘルパー関数: 左右マージ極座標プロット生成 ---\n",
        "def generate_merged_polar_plot(all_results, output_dir_path):\n",
        "    print(\"\\n--- 左右マージ極座標プロットを生成します ---\")\n",
        "    fig_merged_polar, ax_merged_polar = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(8, 8))\n",
        "    has_right_eye_data, has_left_eye_data = False, False\n",
        "\n",
        "    for result_data in all_results:\n",
        "        if result_data.get(\"status\") != \"処理完了\": continue\n",
        "        mpld_mm = result_data.get(\"mpld_mm\", {}); radial_angles = result_data.get(\"radial_angles_deg\", RADIAL_ANGLES_DEG)\n",
        "        eye_side = result_data.get(\"eye_side\", \"Unknown\")\n",
        "\n",
        "        plot_angles_rad, plot_radii_mm = [], []\n",
        "        first_point_angle_rad_orig, first_point_radius_mm_orig = None, None\n",
        "\n",
        "        for angle_deg in radial_angles: # 全周の角度を使う\n",
        "            val_mm = mpld_mm.get(angle_deg, np.nan)\n",
        "            if not np.isnan(val_mm):\n",
        "                current_angle_rad = math.radians(angle_deg)\n",
        "                plot_angle_rad_to_use = current_angle_rad\n",
        "                if eye_side == 'L': # 左眼の場合は角度を水平反転して重ね合わせる\n",
        "                    transformed_angle_deg = normalize_angle_deg(180 - angle_deg)\n",
        "                    plot_angle_rad_to_use = math.radians(transformed_angle_deg)\n",
        "\n",
        "                plot_angles_rad.append(plot_angle_rad_to_use)\n",
        "                plot_radii_mm.append(val_mm)\n",
        "\n",
        "                if angle_deg == 0: # ループを閉じるための元の0度データを保存\n",
        "                    first_point_angle_rad_orig = current_angle_rad\n",
        "                    first_point_radius_mm_orig = val_mm\n",
        "\n",
        "        if not plot_radii_mm: continue\n",
        "\n",
        "        # ループを閉じる処理 (変換後の角度リストに追加)\n",
        "        if first_point_angle_rad_orig is not None and first_point_radius_mm_orig is not None and len(plot_radii_mm) > 1:\n",
        "            final_closing_angle_rad = first_point_angle_rad_orig\n",
        "            if eye_side == 'L': # 左眼の場合、閉じる点も変換後の0度（つまり物理的な180度）\n",
        "                final_closing_angle_rad = math.radians(normalize_angle_deg(180 - 0))\n",
        "            plot_angles_rad.append(final_closing_angle_rad)\n",
        "            plot_radii_mm.append(first_point_radius_mm_orig)\n",
        "\n",
        "        line_color, label_base, has_data_flag = 'gray', '不明な眼', False\n",
        "        if eye_side == 'R': line_color, label_base, has_data_flag = 'blue', '右眼', has_right_eye_data\n",
        "        elif eye_side == 'L': line_color, label_base, has_data_flag = 'red', '左眼 (表示反転)', has_left_eye_data # ラベル変更\n",
        "\n",
        "        current_label = f'{label_base} MPLD' if not has_data_flag else None # 凡例は初回のみ\n",
        "        ax_merged_polar.plot(plot_angles_rad, plot_radii_mm, marker='o' if not has_data_flag else '.', linestyle='-', color=line_color, label=current_label, alpha=1.0 if not has_data_flag else 0.6)\n",
        "        if eye_side == 'R' and not has_right_eye_data: has_right_eye_data = True\n",
        "        if eye_side == 'L' and not has_left_eye_data: has_left_eye_data = True\n",
        "\n",
        "    if not has_right_eye_data and not has_left_eye_data:\n",
        "        print(\"  左右マージプロット用の有効なデータがありませんでした。\")\n",
        "        plt.close(fig_merged_polar) # プロットウィンドウを閉じる\n",
        "        return\n",
        "\n",
        "    ax_merged_polar.set_theta_zero_location(\"E\"); ax_merged_polar.set_theta_direction(1)\n",
        "    angle_ticks_to_display = RADIAL_ANGLES_DEG[::3]; ax_merged_polar.set_xticks(np.deg2rad(angle_ticks_to_display))\n",
        "    ax_merged_polar.set_xticklabels([f\"{angle}°\" for angle in angle_ticks_to_display])\n",
        "\n",
        "    all_radii_for_rmax = [r for res in all_results if res.get(\"status\") == \"処理完了\" for r_list in [res.get(\"mpld_mm\", {}).values()] for r in r_list if not np.isnan(r)]\n",
        "    if all_radii_for_rmax:\n",
        "        max_r_val = max(all_radii_for_rmax) if all_radii_for_rmax else 5.0\n",
        "        ax_merged_polar.set_rmax(math.ceil(max_r_val * 1.1 if max_r_val > 0 else 5.0))\n",
        "    else: ax_merged_polar.set_rmax(5.0)\n",
        "    ax_merged_polar.set_title(f\"左右MPLDマージプロット (mm)\", va='bottom', pad=20); ax_merged_polar.legend()\n",
        "    merged_plot_filename = os.path.join(output_dir_path, f\"mrmpd_merged_polar_plot.png\")\n",
        "    try: fig_merged_polar.savefig(merged_plot_filename); print(f\"  左右マージ極座標プロットを保存しました: {merged_plot_filename}\")\n",
        "    except Exception as e: print(f\"  左右マージ極座標プロットの保存に失敗しました: {e}\")\n",
        "    plt.show()\n",
        "\n",
        "# --- メイン処理開始 ---\n",
        "# 1. モデルのロード\n",
        "print(\"--- モデルのロードを開始します ---\")\n",
        "try:\n",
        "    detect_model = YOLO(detect_model_path)\n",
        "    print(f\"Detection model '{detect_model_path}' loaded successfully.\")\n",
        "    print(f\"  【確認】detect_model クラス名: {detect_model.names}\")\n",
        "    seg_model = YOLO(seg_model_path)\n",
        "    print(f\"Segmentation model '{seg_model_path}' loaded successfully.\")\n",
        "    print(f\"  【確認】seg_model クラス名: {seg_model.names}\")\n",
        "    obb_model = YOLO(obb_model_path)\n",
        "    print(f\"OBB model '{obb_model_path}' loaded successfully.\")\n",
        "    print(f\"  【確認】obb_model クラス名: {obb_model.names}\")\n",
        "except Exception as e:\n",
        "    print(f\"モデルのロード中にエラーが発生しました: {e}\"); exit()\n",
        "\n",
        "# 2. 画像のロード\n",
        "print(f\"\\n--- 画像 '{image_path}' のロードを開始 ---\")\n",
        "try:\n",
        "    img_pil_original = Image.open(image_path).convert(\"RGB\")\n",
        "    img_cv_original_rgb = np.array(img_pil_original)\n",
        "    original_img_h, original_img_w = img_cv_original_rgb.shape[:2]\n",
        "    print(f\"Image '{image_path}' loaded. Dimensions: {original_img_w}x{original_img_h}\")\n",
        "except Exception as e:\n",
        "    print(f\"画像のロード中にエラー: {e}\"); exit()\n",
        "\n",
        "# 3. 元画像の表示\n",
        "plt.figure(figsize=(8, 8)); plt.imshow(img_pil_original)\n",
        "plt.title(f\"元画像: {os.path.basename(image_path)}\"); plt.axis(\"off\"); plt.show()\n",
        "\n",
        "# 4. 物体検出の実行 (detect_model)\n",
        "print(\"\\n--- 物体検出を実行中 (detect_model) ---\")\n",
        "detect_results_list = detect_model(img_pil_original, verbose=False, conf=0.3)\n",
        "if not detect_results_list or len(detect_results_list[0].boxes) == 0:\n",
        "    print(\"物体が検出されませんでした。処理を終了します。\"); exit()\n",
        "detect_result_obj = detect_results_list[0]\n",
        "print(\"物体検出完了。\")\n",
        "\n",
        "# 5. BBoxの処理と画像の切り抜き & 左右眼判定\n",
        "cropped_images_info_list = []\n",
        "boxes_xyxy = detect_result_obj.boxes.xyxy.cpu().numpy()\n",
        "class_indices = detect_result_obj.boxes.cls.cpu().numpy().astype(int)\n",
        "print(f\"{len(boxes_xyxy)} 個のバウンディングボックスが見つかりました。\")\n",
        "\n",
        "for i in range(len(boxes_xyxy)):\n",
        "    box = boxes_xyxy[i]; x1, y1, x2, y2 = map(int, box)\n",
        "    cls_idx = class_indices[i]; class_name = detect_model.names[cls_idx]\n",
        "    eye_side = \"Unknown\"\n",
        "    if class_name == 'Left_eye': eye_side = \"L\"\n",
        "    elif class_name == 'Right_eye': eye_side = \"R\"\n",
        "    print(f\"\\nBBox {i+1} 処理中: Class='{class_name}', Side='{eye_side}'\")\n",
        "    bbox_width = x2 - x1; bbox_height = y2 - y1\n",
        "    if bbox_width <= 0 or bbox_height <= 0: print(f\"  無効なBBoxサイズ。スキップ。\"); continue\n",
        "    bbox_center_x = x1 + bbox_width / 2.0; bbox_center_y = y1 + bbox_height / 2.0\n",
        "    new_width = int(round(bbox_width * 1.5)); new_height = new_width\n",
        "    crop_x1 = int(round(bbox_center_x - new_width / 2.0)); crop_y1 = int(round(bbox_center_y - new_height / 2.0))\n",
        "    crop_x2 = crop_x1 + new_width; crop_y2 = crop_y1 + new_height\n",
        "    slice_x1 = max(0, crop_x1); slice_y1 = max(0, crop_y1)\n",
        "    slice_x2 = min(original_img_w, crop_x2); slice_y2 = min(original_img_h, crop_y2)\n",
        "    cropped_part_final = None\n",
        "    if slice_x1 >= slice_x2 or slice_y1 >= slice_y2:\n",
        "        print(f\"  有効な切り取り領域なし。サイズ {new_width}x{new_height} の黒画像を生成。\")\n",
        "        cropped_part_final = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
        "    else:\n",
        "        img_slice = img_cv_original_rgb[slice_y1:slice_y2, slice_x1:slice_x2]\n",
        "        if img_slice.size == 0:\n",
        "             print(f\"  切り出し部分サイズ0。黒画像生成。\"); cropped_part_final = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            pad_left = max(0, -crop_x1); pad_top = max(0, -crop_y1)\n",
        "            pad_right = max(0, crop_x2 - original_img_w); pad_bottom = max(0, crop_y2 - original_img_h)\n",
        "            cropped_part_with_border = cv2.copyMakeBorder(img_slice, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
        "            if cropped_part_with_border.shape[0] != new_height or cropped_part_with_border.shape[1] != new_width:\n",
        "                cropped_part_final = cv2.resize(cropped_part_with_border, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
        "            else:\n",
        "                cropped_part_final = cropped_part_with_border\n",
        "    if cropped_part_final is not None:\n",
        "        cropped_image_pil_object = Image.fromarray(cropped_part_final)\n",
        "        cropped_image_pil_object.filename = f\"{os.path.basename(image_path)}_bbox{i+1}_{eye_side}\"\n",
        "        cropped_images_info_list.append({\"image\": cropped_image_pil_object, \"eye_side\": eye_side, \"original_bbox_index\": i, \"source_filename\": os.path.basename(image_path)})\n",
        "        print(f\"  クロップ画像 {i+1} (Side: {eye_side}) 生成完了。Shape: {cropped_part_final.shape[:2]}\")\n",
        "    else: print(f\"  クロップ画像 {i+1} (Side: {eye_side}) 生成失敗。\")\n",
        "print(f\"\\n{len(cropped_images_info_list)} 個のクロップ画像を生成 (左右情報含む)。\")\n",
        "\n",
        "# 6. 切り抜いた画像の表示\n",
        "if cropped_images_info_list:\n",
        "    num_cropped = len(cropped_images_info_list)\n",
        "    cols = min(num_cropped, 3); rows = (num_cropped + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 6 * rows), squeeze=False)\n",
        "    axes = axes.ravel()\n",
        "    for i, img_info in enumerate(cropped_images_info_list):\n",
        "        axes[i].imshow(img_info[\"image\"])\n",
        "        axes[i].set_title(f\"Cropped {i+1} (Side: {img_info['eye_side']})\"); axes[i].axis(\"off\")\n",
        "    for j in range(num_cropped, len(axes)): axes[j].axis(\"off\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "    print(f\"{num_cropped} 個のクロップ画像を表示。\")\n",
        "else: print(\"表示するクロップ画像なし。\")\n",
        "\n",
        "# --- MRMPD解析メイン処理 ---\n",
        "print(\"\\n--- MRMPD解析を開始します (メイン処理) ---\")\n",
        "if not cropped_images_info_list: print(\"MRMPD解析対象のクロップ画像なし。終了。\"); exit()\n",
        "all_mrmpd_results_data = []\n",
        "\n",
        "for img_idx, img_info in enumerate(cropped_images_info_list):\n",
        "    pil_image_clean_crop = img_info[\"image\"]; eye_side_detected = img_info[\"eye_side\"]\n",
        "    source_file_basename = os.path.splitext(img_info[\"source_filename\"])[0]\n",
        "    debug_img_id_str = f\"{source_file_basename}_bbox{img_info['original_bbox_index']+1}_{eye_side_detected}\"\n",
        "    print(f\"\\n--- 画像 {debug_img_id_str} のMRMPD解析を開始 ---\")\n",
        "    current_mrmpd_data = {\"image_id\": debug_img_id_str, \"status\": \"処理開始\", \"eye_side\": eye_side_detected}\n",
        "    img_np_rgb = np.array(pil_image_clean_crop.convert(\"RGB\")); img_h, img_w = img_np_rgb.shape[:2]\n",
        "    pupil_center, pixels_per_mm = None, None\n",
        "    try:\n",
        "        obb_results_list = obb_model(pil_image_clean_crop, verbose=False, conf=0.25)\n",
        "        if not obb_results_list: raise ValueError(\"OBBモデル結果なし\")\n",
        "        obb_result_obj = obb_results_list[0]\n",
        "        pupil_obb_data = get_obb_data_by_class_name(obb_result_obj, OBB_CLASS_PUPIL, obb_model.names, debug_img_id_str)\n",
        "        if not pupil_obb_data: raise ValueError(f\"'{OBB_CLASS_PUPIL}' OBBなし\")\n",
        "        pupil_center = (int(round(pupil_obb_data[\"center_x\"])), int(round(pupil_obb_data[\"center_y\"])))\n",
        "        current_mrmpd_data[\"pupil_center_px\"] = pupil_center; print(f\"  瞳孔中心: {pupil_center}\")\n",
        "        iris_obb_data = get_obb_data_by_class_name(obb_result_obj, OBB_CLASS_IRIS, obb_model.names, debug_img_id_str)\n",
        "        if not iris_obb_data: raise ValueError(f\"'{OBB_CLASS_IRIS}' OBBなし\")\n",
        "        major_axis_pixels = max(iris_obb_data[\"width\"], iris_obb_data[\"height\"])\n",
        "        if not major_axis_pixels > 0: raise ValueError(f\"'{OBB_CLASS_IRIS}' OBB長径0\")\n",
        "        pixels_per_mm = major_axis_pixels / CORNEAL_DIAMETER_MM\n",
        "        current_mrmpd_data[\"pixels_per_mm\"] = pixels_per_mm; current_mrmpd_data[\"iris_major_axis_px\"] = major_axis_pixels\n",
        "        print(f\"  虹彩長径: {major_axis_pixels:.2f}px。スケール: {pixels_per_mm:.2f} px/mm\")\n",
        "    except Exception as e: error_msg = f\"OBB処理エラー: {e}\"; print(f\"エラー (画像 {debug_img_id_str}): {error_msg}\"); current_mrmpd_data.update({\"error\": error_msg, \"status\": \"OBBエラー\"}); all_mrmpd_results_data.append(current_mrmpd_data); continue\n",
        "\n",
        "    eyelid_mask_area = None\n",
        "    try:\n",
        "        seg_results_list = seg_model(pil_image_clean_crop, verbose=False, conf=0.25, retina_masks=True)\n",
        "        if not seg_results_list: raise ValueError(\"Segモデル結果なし\")\n",
        "        seg_result_obj = seg_results_list[0]\n",
        "        eyelid_mask_area = get_mask_by_class_name(seg_result_obj, SEG_CLASS_EYELID, seg_model.names, (img_h, img_w), debug_img_id_str)\n",
        "        if eyelid_mask_area is None: raise ValueError(f\"'{SEG_CLASS_EYELID}' マスクなし\")\n",
        "        print(f\"  '{SEG_CLASS_EYELID}' マスク取得成功。\")\n",
        "    except Exception as e: error_msg = f\"Seg処理エラー: {e}\"; print(f\"エラー (画像 {debug_img_id_str}): {error_msg}\"); current_mrmpd_data.update({\"error\": error_msg, \"status\": \"Segエラー\"}); all_mrmpd_results_data.append(current_mrmpd_data); continue\n",
        "\n",
        "    angle_inner_end_deg, angle_outer_end_deg = 0.0, 180.0\n",
        "    try:\n",
        "        contours, _ = cv2.findContours(eyelid_mask_area, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if not contours: raise ValueError(\"Eyelid輪郭なし\")\n",
        "        largest_contour = max(contours, key=cv2.contourArea); pupil_cx, pupil_cy = pupil_center\n",
        "        y_tolerance = img_h * 0.15\n",
        "        points_near_pupil_height = [tuple(p[0]) for p_arr in largest_contour for p in [p_arr] if abs(p[0][1] - pupil_cy) <= y_tolerance]\n",
        "        if len(points_near_pupil_height) < 2 : print(f\"  警告 (画像 {debug_img_id_str}): 瞳孔水平線近くのEyelid輪郭点不十分。上まぶた範囲はデフォルト(0-180度)。\")\n",
        "        else:\n",
        "            right_points = [p for p in points_near_pupil_height if p[0] > pupil_cx]\n",
        "            left_points = [p for p in points_near_pupil_height if p[0] < pupil_cx]\n",
        "            if not right_points or not left_points: print(f\"  警告 (画像 {debug_img_id_str}): 瞳孔水平線上で左右両端のEyelid輪郭点なし。上まぶた範囲はデフォルト(0-180度)。\")\n",
        "            else:\n",
        "                inner_end_point = max(right_points, key=lambda p: p[0]); outer_end_point = min(left_points, key=lambda p: p[0])\n",
        "                angle_inner_end_rad = math.atan2(pupil_cy - inner_end_point[1], inner_end_point[0] - pupil_cx)\n",
        "                angle_outer_end_rad = math.atan2(pupil_cy - outer_end_point[1], outer_end_point[0] - pupil_cx)\n",
        "                angle_inner_end_deg = normalize_angle_deg(math.degrees(angle_inner_end_rad))\n",
        "                angle_outer_end_deg = normalize_angle_deg(math.degrees(angle_outer_end_rad))\n",
        "        current_mrmpd_data[\"angle_inner_end_deg\"] = angle_inner_end_deg; current_mrmpd_data[\"angle_outer_end_deg\"] = angle_outer_end_deg\n",
        "        print(f\"  上まぶた端角度(推定): 内端 {angle_inner_end_deg:.1f}°, 外端 {angle_outer_end_deg:.1f}°\")\n",
        "    except Exception as e: print(f\"警告(画像 {debug_img_id_str}): 上まぶた端角度特定エラー: {e}。非対称比は0-180度範囲で処理。\"); current_mrmpd_data[\"angle_determination_error\"] = str(e)\n",
        "\n",
        "    mpld_mm_values = {}; intersection_points_coords = {}; max_search_radius = int(math.sqrt(img_w**2 + img_h**2))\n",
        "    if not (0 <= pupil_cx < img_w and 0 <= pupil_cy < img_h and eyelid_mask_area[pupil_cy, pupil_cx] > 0):\n",
        "        print(f\"警告 (画像 {debug_img_id_str}): 瞳孔中心 ({pupil_center}) がEyelidマスク外または値0。MPLD計算不正確の可能性あり。\")\n",
        "    for angle_deg in RADIAL_ANGLES_DEG:\n",
        "        angle_rad = math.radians(angle_deg); last_known_mask_point = None\n",
        "        current_distance_at_last_mask_point = np.nan; found_exit_point_for_this_angle = False\n",
        "        for r_step in range(1, max_search_radius + 1):\n",
        "            x_curr = int(round(pupil_cx + r_step * math.cos(angle_rad))); y_curr = int(round(pupil_cy - r_step * math.sin(angle_rad)))\n",
        "            if not (0 <= x_curr < img_w and 0 <= y_curr < img_h):\n",
        "                if last_known_mask_point is not None: mpld_mm_values[angle_deg] = current_distance_at_last_mask_point / pixels_per_mm; intersection_points_coords[angle_deg] = last_known_mask_point; found_exit_point_for_this_angle = True\n",
        "                break\n",
        "            if eyelid_mask_area[y_curr, x_curr] > 0: last_known_mask_point = (x_curr, y_curr); current_distance_at_last_mask_point = r_step\n",
        "            else:\n",
        "                if last_known_mask_point is not None: mpld_mm_values[angle_deg] = current_distance_at_last_mask_point / pixels_per_mm; intersection_points_coords[angle_deg] = last_known_mask_point; found_exit_point_for_this_angle = True\n",
        "                break\n",
        "        if not found_exit_point_for_this_angle:\n",
        "            if last_known_mask_point is not None: mpld_mm_values[angle_deg] = current_distance_at_last_mask_point / pixels_per_mm; intersection_points_coords[angle_deg] = last_known_mask_point\n",
        "            else: mpld_mm_values[angle_deg] = np.nan; intersection_points_coords[angle_deg] = None\n",
        "    current_mrmpd_data[\"mpld_mm\"] = mpld_mm_values; current_mrmpd_data[\"intersections_px\"] = intersection_points_coords\n",
        "    current_mrmpd_data[\"radial_angles_deg\"] = RADIAL_ANGLES_DEG; print(f\"  MPLD計算完了（全周）。\")\n",
        "\n",
        "    mrd1_mm = mpld_mm_values.get(90.0, np.nan); mrd2_mm = mpld_mm_values.get(270.0, np.nan)\n",
        "    current_mrmpd_data[\"MRD1_mm\"] = mrd1_mm; current_mrmpd_data[\"MRD2_mm\"] = mrd2_mm\n",
        "    print(f\"  MRD-1 (90°): {mrd1_mm:.2f} mm\" if not np.isnan(mrd1_mm) else \"  MRD-1 (90°): N/A\")\n",
        "    print(f\"  MRD-2 (270°): {mrd2_mm:.2f} mm\" if not np.isnan(mrd2_mm) else \"  MRD-2 (270°): N/A\")\n",
        "\n",
        "    img_viz_mrmpd_pil = pil_image_clean_crop.copy().convert(\"RGB\"); draw = ImageDraw.Draw(img_viz_mrmpd_pil)\n",
        "    draw.ellipse((pupil_cx-3, pupil_cy-3, pupil_cx+3, pupil_cy+3), fill=\"red\", outline=\"red\")\n",
        "    for angle_deg in RADIAL_ANGLES_DEG:\n",
        "        int_pt = intersection_points_coords.get(angle_deg); line_color = \"yellow\"\n",
        "        if angle_deg == 90.0 and int_pt: line_color = \"lime\"\n",
        "        if angle_deg == 270.0 and int_pt: line_color = \"green\"\n",
        "        if int_pt: draw.line([(pupil_cx, pupil_cy), int_pt], fill=line_color, width=2); draw.ellipse((int_pt[0]-3, int_pt[1]-3, int_pt[0]+3, int_pt[1]+3), fill=\"cyan\", outline=\"cyan\")\n",
        "        else: angle_rad = math.radians(angle_deg); end_x_no_int = int(round(pupil_cx + 30 * math.cos(angle_rad))); end_y_no_int = int(round(pupil_cy - 30 * math.sin(angle_rad))); draw.line([(pupil_cx, pupil_cy), (end_x_no_int, end_y_no_int)], fill=(128,128,128,180), width=1)\n",
        "    plt.figure(figsize=(8, 8)); plt.imshow(img_viz_mrmpd_pil)\n",
        "    title_str = f\"MRMPD解析結果 - 画像 {debug_img_id_str}\"\n",
        "    if not np.isnan(mrd1_mm): title_str += f\"\\nMRD1: {mrd1_mm:.2f}mm\"\n",
        "    if not np.isnan(mrd2_mm): title_str += f\", MRD2: {mrd2_mm:.2f}mm\"\n",
        "    plt.title(title_str); plt.axis(\"off\"); viz_filename = os.path.join(output_dir, f\"mrmpd_visualization_{debug_img_id_str}.png\")\n",
        "    try: img_viz_mrmpd_pil.save(viz_filename); print(f\"  可視化画像を保存: {viz_filename}\")\n",
        "    except Exception as e: print(f\"  可視化画像保存失敗: {e}\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- 5b. 個別極座標プロット (左眼の場合の軸ラベル修正) ---\n",
        "    valid_plot_angles_rad, valid_plot_radii_mm = [], []\n",
        "    first_point_angle_rad_indiv, first_point_radius_mm_indiv = None, None\n",
        "    for angle_deg_plot in RADIAL_ANGLES_DEG:\n",
        "        val_mm = mpld_mm_values.get(angle_deg_plot, np.nan)\n",
        "        if not np.isnan(val_mm):\n",
        "            current_angle_rad = math.radians(angle_deg_plot)\n",
        "            valid_plot_angles_rad.append(current_angle_rad); valid_plot_radii_mm.append(val_mm)\n",
        "            if angle_deg_plot == 0: first_point_angle_rad_indiv, first_point_radius_mm_indiv = current_angle_rad, val_mm\n",
        "    if valid_plot_radii_mm:\n",
        "        if first_point_angle_rad_indiv is not None and first_point_radius_mm_indiv is not None and len(valid_plot_radii_mm) > 1:\n",
        "            valid_plot_angles_rad.append(first_point_angle_rad_indiv); valid_plot_radii_mm.append(first_point_radius_mm_indiv)\n",
        "\n",
        "        fig_polar, ax_polar = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(7, 7))\n",
        "        ax_polar.plot(valid_plot_angles_rad, valid_plot_radii_mm, marker='o', linestyle='-')\n",
        "\n",
        "        # 軸の向きとラベルを設定\n",
        "        ax_polar.set_theta_zero_location(\"E\")  # 物理的な0度(プロット基準)は東(右)\n",
        "        ax_polar.set_theta_direction(1)      # 角度は反時計回り (標準)\n",
        "\n",
        "        # 表示する目盛りの物理的な角度 (画像座標系)\n",
        "        angle_ticks_physical_deg = np.array(RADIAL_ANGLES_DEG[::3]) # 例: [0, 45, 90, ...]\n",
        "        ax_polar.set_xticks(np.deg2rad(angle_ticks_physical_deg))\n",
        "\n",
        "        if eye_side_detected == 'L': # ★★★ 左眼の場合のみ軸ラベルを変換 ★★★\n",
        "            tick_labels_for_L_eye = [f\"{int(normalize_angle_deg(180 - angle))}\\u00b0\" for angle in angle_ticks_physical_deg]\n",
        "            ax_polar.set_xticklabels(tick_labels_for_L_eye)\n",
        "            # print(f\"  左眼の個別プロット軸ラベルを調整済。\") # デバッグ用\n",
        "        else: # 右眼または不明\n",
        "            ax_polar.set_xticklabels([f\"{int(angle)}\\u00b0\" for angle in angle_ticks_physical_deg])\n",
        "\n",
        "        if valid_plot_radii_mm:\n",
        "             max_r_val = max(valid_plot_radii_mm) if valid_plot_radii_mm else 5.0\n",
        "             ax_polar.set_rmax(math.ceil(max_r_val * 1.1 if max_r_val > 0 else 5.0))\n",
        "        else: ax_polar.set_rmax(5.0)\n",
        "        ax_polar.set_title(f\"MPLDの極座標プロット (mm) - 画像 {debug_img_id_str}\", va='bottom', pad=20)\n",
        "        polar_plot_filename = os.path.join(output_dir, f\"mrmpd_polar_plot_{debug_img_id_str}.png\")\n",
        "        try: fig_polar.savefig(polar_plot_filename); print(f\"  極座標プロットを保存: {polar_plot_filename}\")\n",
        "        except Exception as e: print(f\"  極座標プロット保存失敗: {e}\")\n",
        "        plt.show()\n",
        "    else: print(f\"  画像 {debug_img_id_str} の極座標プロット用有効データなし。\")\n",
        "\n",
        "    # (非対称比計算 ... 変更なし)\n",
        "    asymmetry_ratios_calculated = {}\n",
        "    ratio_angle_pairs = [(105, 75), (120, 60), (135, 45), (150, 30), (165, 15), (180, 0)]\n",
        "    print(\"  左右非対称比 (上まぶたのみ, 側頭側 / 鼻側):\")\n",
        "    if angle_inner_end_deg is not None and angle_outer_end_deg is not None:\n",
        "        # print(f\"    上まぶた角度範囲(推定): 内端 {angle_inner_end_deg:.1f}°～外端 {angle_outer_end_deg:.1f}° でペア評価\") # デバッグ用\n",
        "        for t_angle, n_angle in ratio_angle_pairs:\n",
        "            is_t_in_upper = is_angle_in_upper_lid_range(t_angle, angle_inner_end_deg, angle_outer_end_deg)\n",
        "            is_n_in_upper = is_angle_in_upper_lid_range(n_angle, angle_inner_end_deg, angle_outer_end_deg)\n",
        "            ratio_label = f\"{t_angle}°/{n_angle}°\"\n",
        "            if is_t_in_upper and is_n_in_upper:\n",
        "                temporal_val = mpld_mm_values.get(t_angle, np.nan); nasal_val = mpld_mm_values.get(n_angle, np.nan)\n",
        "                if not np.isnan(temporal_val) and not np.isnan(nasal_val) and nasal_val != 0:\n",
        "                    ratio = temporal_val / nasal_val; asymmetry_ratios_calculated[ratio_label] = ratio; print(f\"    {ratio_label}: {ratio:.2f}\")\n",
        "                else: asymmetry_ratios_calculated[ratio_label] = np.nan; print(f\"    {ratio_label}: N/A (MPLD値不足)\")\n",
        "            else: asymmetry_ratios_calculated[ratio_label] = np.nan;\n",
        "    else: print(\"    上まぶた端角度特定不可のため非対称比計算スキップ。\")\n",
        "    current_mrmpd_data[\"asymmetry_ratios\"] = asymmetry_ratios_calculated\n",
        "    current_mrmpd_data[\"status\"] = \"処理完了\"\n",
        "    all_mrmpd_results_data.append(current_mrmpd_data)\n",
        "\n",
        "print(\"\\n--- MRMPD解析 全画像処理完了 ---\")\n",
        "\n",
        "if all_mrmpd_results_data:\n",
        "    generate_merged_polar_plot(all_mrmpd_results_data, output_dir)\n",
        "else:\n",
        "    print(\"解析結果がないため、左右マージ極座標プロットは生成されません。\")"
      ],
      "metadata": {
        "id": "fuG_Wbdt-PQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Modified MPLD analysis (merge mask image)**"
      ],
      "metadata": {
        "id": "F6wV6ISvX6rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "# ultralytics.YOLO をインポート (YOLOの利用を明示)\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Colabで日本語フォントを使用するための準備 (事前にセルで実行推奨)\n",
        "# !pip install japanize-matplotlib\n",
        "import japanize_matplotlib\n",
        "# !pip install scipy # cdist を使用する場合 (通常Colabにはプリインストール)\n",
        "from scipy.spatial.distance import cdist # 最近傍点探索のため(現在は未使用だが将来的に使う可能性)\n",
        "\n",
        "# --- 1. パス設定 ---\n",
        "# !!!以下のパスはご自身の環境に合わせてください!!!\n",
        "drive_base_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/\"\n",
        "detect_model_path = os.path.join(drive_base_path, \"models/295+cerebhq1-20000_yolo11l.pt\")\n",
        "seg_model_path = os.path.join(drive_base_path, \"models/eyelid_caruncle_yolo11seg_1-139.pt\")\n",
        "obb_model_path = os.path.join(drive_base_path, \"models/yolo11n_obb_1-295_1to139.pt\")\n",
        "image_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_test_images/退行性眼瞼下垂/1065-20150514-73-130021_f6728a8d37efcf237c38e21309bb4ec7535a838429b7448eddfcc2b1fcc17e68.jpg\" # 解析したい画像\n",
        "\n",
        "# --- 定数定義 ---\n",
        "OBB_CLASS_PUPIL = 'Pupil'\n",
        "OBB_CLASS_IRIS = 'Iris'\n",
        "SEG_CLASS_EYELID = 'Eyelid'\n",
        "CORNEAL_DIAMETER_MM = 12.0\n",
        "RADIAL_ANGLES_DEG = [i * 15 for i in range(24)] # 0°から345°まで15°間隔\n",
        "\n",
        "# --- 出力ディレクトリ作成 ---\n",
        "output_dir = \"/content/mrmpd_analysis_results\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"結果は '{output_dir}' ディレクトリに保存されます。\")\n",
        "\n",
        "# --- ヘルパー関数 (get_obb_data_by_class_name, get_mask_by_class_name, normalize_angle_deg, is_angle_in_upper_lid_range は変更なし) ---\n",
        "def get_obb_data_by_class_name(obb_results_obj, target_class_name, model_obb_names, img_idx_for_debug=\"N/A\"):\n",
        "    if obb_results_obj is None or not hasattr(obb_results_obj, 'obb') or obb_results_obj.obb is None or \\\n",
        "       not hasattr(obb_results_obj.obb, 'cls') or len(obb_results_obj.obb.cls) == 0: return None\n",
        "    target_cls_indices = []\n",
        "    if isinstance(model_obb_names, dict):\n",
        "        for cls_id, name in model_obb_names.items():\n",
        "            if name == target_class_name: target_cls_indices.append(int(cls_id))\n",
        "    elif isinstance(model_obb_names, list):\n",
        "        for cls_id, name in enumerate(model_obb_names):\n",
        "            if name == target_class_name: target_cls_indices.append(cls_id)\n",
        "    else: print(f\"警告 (画像 {img_idx_for_debug}, get_obb_data): model_obb_names の形式が不明: {type(model_obb_names)}\"); return None\n",
        "    if not target_cls_indices: return None\n",
        "    best_obb_data = None; highest_conf = -1.0\n",
        "    if not hasattr(obb_results_obj.obb, 'conf') or not hasattr(obb_results_obj.obb, 'xywhr'): return None\n",
        "    detected_classes = obb_results_obj.obb.cls.cpu().numpy().astype(int)\n",
        "    confidences = obb_results_obj.obb.conf.cpu().numpy(); xywhr_data = obb_results_obj.obb.xywhr.cpu().numpy()\n",
        "    found_instances = 0\n",
        "    for i in range(len(detected_classes)):\n",
        "        if detected_classes[i] in target_cls_indices:\n",
        "            found_instances +=1; current_conf = confidences[i]\n",
        "            if current_conf > highest_conf:\n",
        "                highest_conf = current_conf\n",
        "                best_obb_data = {\"center_x\": xywhr_data[i][0], \"center_y\": xywhr_data[i][1], \"width\": xywhr_data[i][2], \"height\": xywhr_data[i][3], \"angle_rad\": xywhr_data[i][4], \"confidence\": current_conf }\n",
        "    return best_obb_data if found_instances > 0 and best_obb_data is not None else None\n",
        "\n",
        "def get_mask_by_class_name(seg_results_obj, target_class_name, model_seg_names, target_shape_hw, img_idx_for_debug=\"N/A\"):\n",
        "    if seg_results_obj.masks is None: return None\n",
        "    if not hasattr(seg_results_obj.masks, 'data') or seg_results_obj.masks.data is None: return None\n",
        "    if seg_results_obj.boxes is None: return None # boxesがNoneの場合のチェックを追加\n",
        "    target_cls_indices = []\n",
        "    if isinstance(model_seg_names, dict):\n",
        "        for cls_id, name in model_seg_names.items():\n",
        "            if name == target_class_name: target_cls_indices.append(int(cls_id))\n",
        "    elif isinstance(model_seg_names, list):\n",
        "        for cls_id, name in enumerate(model_seg_names):\n",
        "            if name == target_class_name: target_cls_indices.append(cls_id)\n",
        "    else: print(f\"警告 (画像 {img_idx_for_debug}, get_mask): model_seg_names の形式が不明: {type(model_seg_names)}\"); return None\n",
        "    if not target_cls_indices: return None\n",
        "    relevant_masks_data = []\n",
        "    all_detected_cls_indices = seg_results_obj.boxes.cls.cpu().numpy().astype(int)\n",
        "    raw_masks_tensor = seg_results_obj.masks.data\n",
        "    if raw_masks_tensor is None or len(raw_masks_tensor) == 0: return None\n",
        "    num_to_iterate = min(len(all_detected_cls_indices), raw_masks_tensor.shape[0])\n",
        "    if len(all_detected_cls_indices) != raw_masks_tensor.shape[0]: print(f\"警告 (画像 {img_idx_for_debug}, get_mask): ボックス数とマスク数が不一致。短い方({num_to_iterate})で処理。\")\n",
        "    for i in range(num_to_iterate):\n",
        "        current_model_cls_idx = all_detected_cls_indices[i]\n",
        "        if current_model_cls_idx in target_cls_indices:\n",
        "            try:\n",
        "                mask_proto = raw_masks_tensor[i]; mask_proto_tensor = mask_proto.unsqueeze(0).unsqueeze(0)\n",
        "                if mask_proto_tensor.shape[2:] == target_shape_hw: upsampled_mask_tensor = mask_proto_tensor.squeeze()\n",
        "                else: upsampled_mask_tensor = torch.nn.functional.interpolate(mask_proto_tensor, size=target_shape_hw, mode='bilinear', align_corners=False).squeeze()\n",
        "                mask_np = upsampled_mask_tensor.cpu().numpy(); mask_np_binary = (mask_np > 0.5).astype(np.uint8) * 255\n",
        "                contours, _ = cv2.findContours(mask_np_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # 変数名変更\n",
        "                area = sum(cv2.contourArea(c) for c in contours) if contours else 0\n",
        "                if area > 0: relevant_masks_data.append({'mask': mask_np_binary, 'area': area})\n",
        "            except Exception as e: print(f\"エラー (画像 {img_idx_for_debug}, get_mask): '{target_class_name}' のインスタンス {i} のマスク処理中に例外: {e}\"); continue\n",
        "    if not relevant_masks_data: return None\n",
        "    largest_mask_data = max(relevant_masks_data, key=lambda x: x['area'])\n",
        "    return largest_mask_data['mask']\n",
        "\n",
        "def normalize_angle_deg(angle_deg):\n",
        "    angle = angle_deg % 360\n",
        "    return angle if angle >= 0 else angle + 360\n",
        "\n",
        "def is_angle_in_upper_lid_range(angle_deg_to_check, inner_end_deg, outer_end_deg):\n",
        "    angle = normalize_angle_deg(angle_deg_to_check); start = normalize_angle_deg(inner_end_deg); end = normalize_angle_deg(outer_end_deg)\n",
        "    if start <= end: return start <= angle <= end\n",
        "    else: return angle >= start or angle <= end\n",
        "\n",
        "# --- ヘルパー関数: 左右マージ極座標プロット生成 (更新) ---\n",
        "def generate_merged_polar_plot(all_results, output_dir_path):\n",
        "    print(\"\\n--- 左右マージ極座標プロットを生成します ---\")\n",
        "    fig_merged_polar, ax_merged_polar = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(10, 10)) # サイズ調整\n",
        "    has_right_eye_mpld_data, has_left_eye_mpld_data = False, False\n",
        "    has_right_contour_data, has_left_contour_data = False, False\n",
        "\n",
        "    for result_data in all_results:\n",
        "        if result_data.get(\"status\") != \"処理完了\":\n",
        "            continue\n",
        "\n",
        "        mpld_mm = result_data.get(\"mpld_mm\", {})\n",
        "        radial_angles_deg_list = result_data.get(\"radial_angles_deg\", RADIAL_ANGLES_DEG)\n",
        "        eye_side = result_data.get(\"eye_side\", \"Unknown\")\n",
        "\n",
        "        # --- MPLDデータのプロット ---\n",
        "        plot_angles_rad, plot_radii_mm = [], []\n",
        "        first_point_angle_rad_orig, first_point_radius_mm_orig = None, None\n",
        "\n",
        "        for angle_deg in radial_angles_deg_list:\n",
        "            val_mm = mpld_mm.get(angle_deg, np.nan)\n",
        "            if not np.isnan(val_mm):\n",
        "                current_angle_rad = math.radians(angle_deg)\n",
        "                plot_angle_rad_to_use = current_angle_rad\n",
        "                if eye_side == 'L': # 左眼の場合は角度を水平反転\n",
        "                    transformed_angle_deg = normalize_angle_deg(180 - angle_deg)\n",
        "                    plot_angle_rad_to_use = math.radians(transformed_angle_deg)\n",
        "\n",
        "                plot_angles_rad.append(plot_angle_rad_to_use)\n",
        "                plot_radii_mm.append(val_mm)\n",
        "\n",
        "                if angle_deg == 0: # ループを閉じるための元の0度データを保存\n",
        "                    first_point_angle_rad_orig = current_angle_rad\n",
        "                    first_point_radius_mm_orig = val_mm\n",
        "\n",
        "        if plot_radii_mm: # 有効なMPLDデータがある場合のみプロット\n",
        "            # ループを閉じる処理 (変換後の角度リストに追加)\n",
        "            if first_point_angle_rad_orig is not None and first_point_radius_mm_orig is not None and len(plot_radii_mm) > 1:\n",
        "                final_closing_angle_rad = first_point_angle_rad_orig\n",
        "                if eye_side == 'L': # 左眼の場合、閉じる点も変換後の0度（つまり物理的な180度）\n",
        "                    final_closing_angle_rad = math.radians(normalize_angle_deg(180 - 0))\n",
        "                plot_angles_rad.append(final_closing_angle_rad)\n",
        "                plot_radii_mm.append(first_point_radius_mm_orig)\n",
        "\n",
        "            line_color_mpld, label_base_mpld, has_data_flag_ref_mpld = 'gray', '不明眼MPLD', False\n",
        "            if eye_side == 'R':\n",
        "                line_color_mpld, label_base_mpld, has_data_flag_ref_mpld = 'blue', '右眼 MPLD', has_right_eye_mpld_data\n",
        "            elif eye_side == 'L':\n",
        "                line_color_mpld, label_base_mpld, has_data_flag_ref_mpld = 'red', '左眼 MPLD (表示反転)', has_left_eye_mpld_data\n",
        "\n",
        "            current_label_mpld = label_base_mpld if not has_data_flag_ref_mpld else None\n",
        "            ax_merged_polar.plot(plot_angles_rad, plot_radii_mm,\n",
        "                                 marker='.' if has_data_flag_ref_mpld else 'o',\n",
        "                                 linestyle='-', color=line_color_mpld, label=current_label_mpld,\n",
        "                                 alpha=0.6 if has_data_flag_ref_mpld else 0.9,\n",
        "                                 markersize=4 if has_data_flag_ref_mpld else 6,\n",
        "                                 zorder=10) # MPLDを前面に\n",
        "\n",
        "            if eye_side == 'R' and not has_right_eye_mpld_data: has_right_eye_mpld_data = True\n",
        "            if eye_side == 'L' and not has_left_eye_mpld_data: has_left_eye_mpld_data = True\n",
        "\n",
        "        # --- Eyelidマスク輪郭データのプロット ---\n",
        "        contour_theta_rad_list = result_data.get(\"eyelid_contour_theta_rad\", [])\n",
        "        contour_r_mm_list = result_data.get(\"eyelid_contour_r_mm\", [])\n",
        "\n",
        "        if contour_theta_rad_list and contour_r_mm_list:\n",
        "            plot_contour_angles_rad, plot_contour_radii_mm = [], []\n",
        "\n",
        "            if eye_side == 'L': # 左眼の場合は輪郭の角度も水平反転\n",
        "                for theta_rad in contour_theta_rad_list:\n",
        "                    original_angle_deg = math.degrees(theta_rad)\n",
        "                    transformed_angle_deg = normalize_angle_deg(180 - original_angle_deg)\n",
        "                    plot_contour_angles_rad.append(math.radians(transformed_angle_deg))\n",
        "                plot_contour_radii_mm = contour_r_mm_list\n",
        "            else: # 右眼または不明な場合はそのまま\n",
        "                plot_contour_angles_rad = contour_theta_rad_list\n",
        "                plot_contour_radii_mm = contour_r_mm_list\n",
        "\n",
        "            line_color_contour, label_base_contour, has_data_flag_ref_contour = 'darkgrey', '不明眼 輪郭', False\n",
        "            contour_alpha = 0.5\n",
        "            if eye_side == 'R':\n",
        "                line_color_contour, label_base_contour, has_data_flag_ref_contour = 'cyan', '右眼 輪郭', has_right_contour_data\n",
        "            elif eye_side == 'L':\n",
        "                line_color_contour, label_base_contour, has_data_flag_ref_contour = 'magenta', '左眼 輪郭 (表示反転)', has_left_contour_data\n",
        "\n",
        "            current_label_contour = label_base_contour if not has_data_flag_ref_contour else None\n",
        "            ax_merged_polar.plot(plot_contour_angles_rad, plot_contour_radii_mm,\n",
        "                                 linestyle='-', color=line_color_contour, label=current_label_contour,\n",
        "                                 alpha=contour_alpha, linewidth=2, zorder=5) # 輪郭はMPLDより奥\n",
        "\n",
        "            if eye_side == 'R' and not has_right_contour_data: has_right_contour_data = True\n",
        "            if eye_side == 'L' and not has_left_contour_data: has_left_contour_data = True\n",
        "\n",
        "    if not (has_right_eye_mpld_data or has_left_eye_mpld_data or has_right_contour_data or has_left_contour_data):\n",
        "        print(\"  左右マージプロット用の有効なデータがありませんでした。\")\n",
        "        plt.close(fig_merged_polar)\n",
        "        return\n",
        "\n",
        "    ax_merged_polar.set_theta_zero_location(\"E\") # 0度を右(East)に設定\n",
        "    ax_merged_polar.set_theta_direction(1)      # 角度は反時計回り (標準)\n",
        "\n",
        "    # 角度の目盛りラベルを設定 (0度が右になるように)\n",
        "    # 表示する角度のリスト（例: 0, 30, 60, ..., 330）\n",
        "    # RADIAL_ANGLES_DEG は0から345まで15度間隔なので、そのまま使える。45度ごとにするなら RADIAL_ANGLES_DEG[::3]\n",
        "    angle_ticks_to_display = RADIAL_ANGLES_DEG[::3] # 45度ごとにラベル表示\n",
        "    ax_merged_polar.set_xticks(np.deg2rad(angle_ticks_to_display))\n",
        "    ax_merged_polar.set_xticklabels([f\"{angle}°\" for angle in angle_ticks_to_display])\n",
        "\n",
        "    all_radii_for_rmax = []\n",
        "    for res in all_results:\n",
        "        if res.get(\"status\") == \"処理完了\":\n",
        "            mpld_vals = res.get(\"mpld_mm\", {}).values()\n",
        "            all_radii_for_rmax.extend([r for r in mpld_vals if not np.isnan(r)])\n",
        "            contour_r_vals = res.get(\"eyelid_contour_r_mm\", []) # 追加\n",
        "            all_radii_for_rmax.extend([r for r in contour_r_vals if not np.isnan(r) and r is not None])\n",
        "\n",
        "\n",
        "    if all_radii_for_rmax:\n",
        "        max_r_val = max(all_radii_for_rmax) if all_radii_for_rmax else 5.0\n",
        "        ax_merged_polar.set_rmax(math.ceil(max_r_val * 1.15 if max_r_val > 0 else 5.5)) # 少し余裕を持たせる\n",
        "    else:\n",
        "        ax_merged_polar.set_rmax(5.0)\n",
        "\n",
        "    ax_merged_polar.set_title(f\"左右MPLD・Eyelid輪郭 マージプロット (mm)\\n(左眼データは水平反転して表示)\", va='bottom', pad=25)\n",
        "    ax_merged_polar.legend(loc='upper right', bbox_to_anchor=(1.25, 1.05)) # 凡例の位置調整\n",
        "\n",
        "    merged_plot_filename = os.path.join(output_dir_path, f\"mrmpd_merged_polar_plot_with_contours.png\")\n",
        "    try:\n",
        "        fig_merged_polar.savefig(merged_plot_filename, bbox_inches='tight') # bbox_inches='tight' で凡例が切れないように\n",
        "        print(f\"  左右マージ極座標プロット(輪郭付)を保存しました: {merged_plot_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  左右マージ極座標プロット(輪郭付)の保存に失敗しました: {e}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- メイン処理開始 ---\n",
        "# (1. モデルロードから6. クロップ画像表示までは、前回のコードとほぼ同じ)\n",
        "print(\"--- モデルのロードを開始します ---\")\n",
        "try:\n",
        "    detect_model = YOLO(detect_model_path); print(f\"Detection model loaded. Names: {detect_model.names}\")\n",
        "    seg_model = YOLO(seg_model_path); print(f\"Segmentation model loaded. Names: {seg_model.names}\")\n",
        "    obb_model = YOLO(obb_model_path); print(f\"OBB model loaded. Names: {obb_model.names}\")\n",
        "except Exception as e: print(f\"モデルロードエラー: {e}\"); exit()\n",
        "\n",
        "print(f\"\\n--- 画像 '{image_path}' のロードを開始 ---\")\n",
        "try:\n",
        "    img_pil_original = Image.open(image_path).convert(\"RGB\")\n",
        "    img_cv_original_rgb = np.array(img_pil_original)\n",
        "    original_img_h, original_img_w = img_cv_original_rgb.shape[:2]\n",
        "    print(f\"Image loaded: {original_img_w}x{original_img_h}\")\n",
        "except Exception as e: print(f\"画像ロードエラー: {e}\"); exit()\n",
        "\n",
        "plt.figure(figsize=(8, 8)); plt.imshow(img_pil_original); plt.title(f\"元画像: {os.path.basename(image_path)}\"); plt.axis(\"off\"); plt.show()\n",
        "\n",
        "print(\"\\n--- 物体検出を実行中 (detect_model) ---\")\n",
        "detect_results_list = detect_model(img_pil_original, verbose=False, conf=0.3)\n",
        "if not detect_results_list or len(detect_results_list[0].boxes) == 0: print(\"物体検出なし。終了。\"); exit()\n",
        "detect_result_obj = detect_results_list[0]; print(\"物体検出完了。\")\n",
        "\n",
        "cropped_images_info_list = []\n",
        "boxes_xyxy = detect_result_obj.boxes.xyxy.cpu().numpy(); class_indices = detect_result_obj.boxes.cls.cpu().numpy().astype(int)\n",
        "print(f\"{len(boxes_xyxy)} BBox検出。\")\n",
        "for i in range(len(boxes_xyxy)):\n",
        "    box = boxes_xyxy[i]; x1, y1, x2, y2 = map(int, box)\n",
        "    cls_idx = class_indices[i]; class_name = detect_model.names[cls_idx]\n",
        "    eye_side = \"Unknown\";\n",
        "    if class_name == 'Left_eye': eye_side = \"L\"\n",
        "    elif class_name == 'Right_eye': eye_side = \"R\"\n",
        "    print(f\"\\nBBox {i+1}処理中: Class='{class_name}', Side='{eye_side}'\")\n",
        "    bbox_width = x2 - x1; bbox_height = y2 - y1\n",
        "    if bbox_width <= 0 or bbox_height <= 0: print(f\"  無効BBoxサイズ。スキップ。\"); continue\n",
        "    bbox_center_x = x1 + bbox_width / 2.0; bbox_center_y = y1 + bbox_height / 2.0\n",
        "    new_width = int(round(bbox_width * 1.5)); new_height = new_width # 正方形にクロップ\n",
        "    crop_x1 = int(round(bbox_center_x - new_width / 2.0)); crop_y1 = int(round(bbox_center_y - new_height / 2.0))\n",
        "    crop_x2 = crop_x1 + new_width; crop_y2 = crop_y1 + new_height\n",
        "    slice_x1 = max(0, crop_x1); slice_y1 = max(0, crop_y1)\n",
        "    slice_x2 = min(original_img_w, crop_x2); slice_y2 = min(original_img_h, crop_y2)\n",
        "    cropped_part_final = None\n",
        "    if slice_x1 >= slice_x2 or slice_y1 >= slice_y2:\n",
        "        print(f\"  有効な切り取り領域なし。黒画像生成。\"); cropped_part_final = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
        "    else:\n",
        "        img_slice = img_cv_original_rgb[slice_y1:slice_y2, slice_x1:slice_x2]\n",
        "        if img_slice.size == 0: print(f\"  切り出し部分サイズ0。黒画像生成。\"); cropped_part_final = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            pad_left = max(0, -crop_x1); pad_top = max(0, -crop_y1)\n",
        "            pad_right = max(0, crop_x2 - original_img_w); pad_bottom = max(0, crop_y2 - original_img_h)\n",
        "            cropped_part_with_border = cv2.copyMakeBorder(img_slice, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
        "            if cropped_part_with_border.shape[0] != new_height or cropped_part_with_border.shape[1] != new_width:\n",
        "                cropped_part_final = cv2.resize(cropped_part_with_border, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
        "            else: cropped_part_final = cropped_part_with_border\n",
        "    if cropped_part_final is not None:\n",
        "        cropped_image_pil_object = Image.fromarray(cropped_part_final)\n",
        "        cropped_image_pil_object.filename = f\"{os.path.basename(image_path)}_bbox{i+1}_{eye_side}\" # ファイル名をPILオブジェクトに保持\n",
        "        cropped_images_info_list.append({\"image\": cropped_image_pil_object, \"eye_side\": eye_side,\n",
        "                                         \"original_bbox_index\": i, \"source_filename\": os.path.basename(image_path)})\n",
        "        print(f\"  クロップ画像 {i+1} (Side: {eye_side}) 生成完了。Shape: {cropped_part_final.shape[:2]}\")\n",
        "    else: print(f\"  クロップ画像 {i+1} (Side: {eye_side}) 生成失敗。\")\n",
        "print(f\"\\n{len(cropped_images_info_list)} 個のクロップ画像を生成 (左右情報含む)。\")\n",
        "if cropped_images_info_list:\n",
        "    num_cropped = len(cropped_images_info_list)\n",
        "    cols = min(num_cropped, 3); rows = (num_cropped + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 6 * rows), squeeze=False)\n",
        "    axes = axes.ravel()\n",
        "    for i, img_info in enumerate(cropped_images_info_list):\n",
        "        axes[i].imshow(img_info[\"image\"]); axes[i].set_title(f\"Cropped {i+1} (Side: {img_info['eye_side']})\"); axes[i].axis(\"off\")\n",
        "    for j in range(num_cropped, len(axes)): axes[j].axis(\"off\") # 使わないサブプロットを非表示\n",
        "    plt.tight_layout(); plt.show(); print(f\"{num_cropped} 個のクロップ画像を表示。\")\n",
        "else: print(\"表示するクロップ画像なし。\")\n",
        "\n",
        "\n",
        "# --- MPLD解析メイン処理 ---\n",
        "print(\"\\n--- MPLD解析を開始します ---\")\n",
        "if not cropped_images_info_list: print(\"MPLD解析対象のクロップ画像なし。終了。\"); exit()\n",
        "\n",
        "all_mrmpd_results_data = []\n",
        "\n",
        "for img_idx, img_info in enumerate(cropped_images_info_list):\n",
        "    pil_image_clean_crop = img_info[\"image\"]; eye_side_detected = img_info[\"eye_side\"]\n",
        "    source_file_basename = os.path.splitext(img_info[\"source_filename\"])[0]\n",
        "    debug_img_id_str = f\"{source_file_basename}_bbox{img_info['original_bbox_index']+1}_{eye_side_detected}\"\n",
        "    print(f\"\\n--- 画像 {debug_img_id_str} のMPLD解析を開始 ---\")\n",
        "    current_mrmpd_data = {\"image_id\": debug_img_id_str, \"status\": \"処理開始\", \"eye_side\": eye_side_detected}\n",
        "    img_np_rgb = np.array(pil_image_clean_crop.convert(\"RGB\")); img_h, img_w = img_np_rgb.shape[:2]\n",
        "    pupil_center, pixels_per_mm = None, None\n",
        "    try:\n",
        "        obb_results_list = obb_model(pil_image_clean_crop, verbose=False, conf=0.25)\n",
        "        if not obb_results_list: raise ValueError(\"OBBモデル結果なし\")\n",
        "        obb_result_obj = obb_results_list[0]\n",
        "        pupil_obb_data = get_obb_data_by_class_name(obb_result_obj, OBB_CLASS_PUPIL, obb_model.names, debug_img_id_str)\n",
        "        if not pupil_obb_data: raise ValueError(f\"'{OBB_CLASS_PUPIL}' OBBなし\")\n",
        "        pupil_center = (int(round(pupil_obb_data[\"center_x\"])), int(round(pupil_obb_data[\"center_y\"])))\n",
        "        current_mrmpd_data[\"pupil_center_px\"] = pupil_center; print(f\"  瞳孔中心: {pupil_center}\")\n",
        "        iris_obb_data = get_obb_data_by_class_name(obb_result_obj, OBB_CLASS_IRIS, obb_model.names, debug_img_id_str)\n",
        "        if not iris_obb_data: raise ValueError(f\"'{OBB_CLASS_IRIS}' OBBなし\")\n",
        "        major_axis_pixels = max(iris_obb_data[\"width\"], iris_obb_data[\"height\"])\n",
        "        if not major_axis_pixels > 0: raise ValueError(f\"'{OBB_CLASS_IRIS}' OBB長径0\")\n",
        "        pixels_per_mm = major_axis_pixels / CORNEAL_DIAMETER_MM\n",
        "        current_mrmpd_data[\"pixels_per_mm\"] = pixels_per_mm; current_mrmpd_data[\"iris_major_axis_px\"] = major_axis_pixels\n",
        "        print(f\"  虹彩長径: {major_axis_pixels:.2f}px。スケール: {pixels_per_mm:.2f} px/mm\")\n",
        "    except Exception as e: error_msg = f\"OBB処理エラー: {e}\"; print(f\"エラー (画像 {debug_img_id_str}): {error_msg}\"); current_mrmpd_data.update({\"error\": error_msg, \"status\": \"OBBエラー\"}); all_mrmpd_results_data.append(current_mrmpd_data); continue\n",
        "\n",
        "    eyelid_mask_area = None\n",
        "    try:\n",
        "        seg_results_list = seg_model(pil_image_clean_crop, verbose=False, conf=0.25, retina_masks=True)\n",
        "        if not seg_results_list: raise ValueError(\"Segモデル結果なし\")\n",
        "        seg_result_obj = seg_results_list[0]\n",
        "        eyelid_mask_area = get_mask_by_class_name(seg_result_obj, SEG_CLASS_EYELID, seg_model.names, (img_h, img_w), debug_img_id_str)\n",
        "        if eyelid_mask_area is None: raise ValueError(f\"'{SEG_CLASS_EYELID}' マスクなし\")\n",
        "        print(f\"  '{SEG_CLASS_EYELID}' マスク取得成功。\")\n",
        "    except Exception as e: error_msg = f\"Seg処理エラー: {e}\"; print(f\"エラー (画像 {debug_img_id_str}): {error_msg}\"); current_mrmpd_data.update({\"error\": error_msg, \"status\": \"Segエラー\"}); all_mrmpd_results_data.append(current_mrmpd_data); continue\n",
        "\n",
        "    angle_inner_end_deg, angle_outer_end_deg = 0.0, 180.0\n",
        "    try:\n",
        "        contours_mrmpd, _ = cv2.findContours(eyelid_mask_area, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if not contours_mrmpd: raise ValueError(\"Eyelid輪郭なし\")\n",
        "        largest_contour_mrmpd = max(contours_mrmpd, key=cv2.contourArea); pupil_cx, pupil_cy = pupil_center\n",
        "        y_tolerance = img_h * 0.20\n",
        "        points_near_pupil_height = [tuple(p[0]) for p_arr in largest_contour_mrmpd for p in [p_arr] if abs(p[0][1] - pupil_cy) <= y_tolerance]\n",
        "\n",
        "        # デフォルト値（画像端）ではなく、輪郭上の最右／最左点を初期値とする改善も考えられる\n",
        "        default_inner_canthus = tuple(largest_contour_mrmpd[largest_contour_mrmpd[:,:,0].argmax()][0]) # X座標最大\n",
        "        default_outer_canthus = tuple(largest_contour_mrmpd[largest_contour_mrmpd[:,:,0].argmin()][0]) # X座標最小\n",
        "        # 瞳孔中心を基準に内外を判定し、必要なら入れ替え (右目が0度、左目が180度方向が内眼角)\n",
        "        # このデフォルトは、瞳孔中心を無視しているので、後段のロジックで上書きされることを期待\n",
        "        if default_inner_canthus[0] < default_outer_canthus[0]: # X座標で単純比較した場合\n",
        "             default_inner_canthus, default_outer_canthus = default_outer_canthus, default_inner_canthus\n",
        "\n",
        "\n",
        "        if len(points_near_pupil_height) < 2 : print(f\"  警告 (画像 {debug_img_id_str}): 瞳孔水平線近くのEyelid輪郭点不十分。上まぶた範囲はデフォルト(0-180度)。\")\n",
        "        else:\n",
        "            right_points = [p for p in points_near_pupil_height if p[0] > pupil_cx]\n",
        "            left_points = [p for p in points_near_pupil_height if p[0] < pupil_cx]\n",
        "            if not right_points or not left_points: print(f\"  警告 (画像 {debug_img_id_str}): 瞳孔水平線上で左右両端のEyelid輪郭点なし。上まぶた範囲はデフォルト(0-180度)。\")\n",
        "            else:\n",
        "                # 瞳孔中心より右側で最もXが大きい点 = 内眼角側端点 (0度方向)\n",
        "                # 瞳孔中心より左側で最もXが小さい点 = 外眼角側端点 (180度方向)\n",
        "                inner_end_point = max(right_points, key=lambda p: p[0])\n",
        "                outer_end_point = min(left_points, key=lambda p: p[0])\n",
        "\n",
        "                angle_inner_end_rad = math.atan2(pupil_cy - inner_end_point[1], inner_end_point[0] - pupil_cx)\n",
        "                angle_outer_end_rad = math.atan2(pupil_cy - outer_end_point[1], outer_end_point[0] - pupil_cx)\n",
        "                angle_inner_end_deg = normalize_angle_deg(math.degrees(angle_inner_end_rad))\n",
        "                angle_outer_end_deg = normalize_angle_deg(math.degrees(angle_outer_end_rad))\n",
        "        current_mrmpd_data[\"angle_inner_end_deg\"] = angle_inner_end_deg; current_mrmpd_data[\"angle_outer_end_deg\"] = angle_outer_end_deg\n",
        "        print(f\"  上まぶた端角度(推定): 内端 {angle_inner_end_deg:.1f}°, 外端 {angle_outer_end_deg:.1f}°\")\n",
        "    except Exception as e: print(f\"警告(画像 {debug_img_id_str}): 上まぶた端角度特定エラー: {e}。非対称比は0-180度範囲で処理。\"); current_mrmpd_data[\"angle_determination_error\"] = str(e)\n",
        "\n",
        "    mpld_mm_values = {}; intersection_points_coords = {}; max_search_radius = int(math.sqrt(img_w**2 + img_h**2))\n",
        "    if not (0 <= pupil_cx < img_w and 0 <= pupil_cy < img_h and eyelid_mask_area[pupil_cy, pupil_cx] > 0):\n",
        "        print(f\"警告 (画像 {debug_img_id_str}): 瞳孔中心 ({pupil_center}) がEyelidマスク外または値0。MPLD計算不正確の可能性あり。\")\n",
        "    for angle_deg in RADIAL_ANGLES_DEG:\n",
        "        angle_rad = math.radians(angle_deg); last_known_mask_point = None\n",
        "        current_distance_at_last_mask_point = np.nan; found_exit_point_for_this_angle = False\n",
        "        for r_step in range(1, max_search_radius + 1): # 1pxずつ探索\n",
        "            x_curr = int(round(pupil_cx + r_step * math.cos(angle_rad))); y_curr = int(round(pupil_cy - r_step * math.sin(angle_rad))) # Y軸は上が正の角度\n",
        "            if not (0 <= x_curr < img_w and 0 <= y_curr < img_h): # 画像範囲外\n",
        "                if last_known_mask_point is not None: # 直前がマスク内なら、そこが境界\n",
        "                    mpld_mm_values[angle_deg] = current_distance_at_last_mask_point / pixels_per_mm\n",
        "                    intersection_points_coords[angle_deg] = last_known_mask_point\n",
        "                    found_exit_point_for_this_angle = True\n",
        "                break\n",
        "            if eyelid_mask_area[y_curr, x_curr] > 0: # マスク内\n",
        "                last_known_mask_point = (x_curr, y_curr)\n",
        "                current_distance_at_last_mask_point = r_step # この時点での瞳孔中心からの直線距離(px)\n",
        "            else: # マスク外に出た\n",
        "                if last_known_mask_point is not None: # 直前がマスク内なら、そこが境界\n",
        "                    mpld_mm_values[angle_deg] = current_distance_at_last_mask_point / pixels_per_mm\n",
        "                    intersection_points_coords[angle_deg] = last_known_mask_point\n",
        "                    found_exit_point_for_this_angle = True\n",
        "                break\n",
        "        if not found_exit_point_for_this_angle: # ループ完遂 (画像端までマスク内だった場合など)\n",
        "            if last_known_mask_point is not None: # 有効な最後のマスク内ポイントがあればそれを使用\n",
        "                mpld_mm_values[angle_deg] = current_distance_at_last_mask_point / pixels_per_mm\n",
        "                intersection_points_coords[angle_deg] = last_known_mask_point\n",
        "            else: # 一度もマスク内に入らなかった (通常ありえないが念のため)\n",
        "                mpld_mm_values[angle_deg] = np.nan\n",
        "                intersection_points_coords[angle_deg] = None\n",
        "    current_mrmpd_data[\"mpld_mm\"] = mpld_mm_values; current_mrmpd_data[\"intersections_px\"] = intersection_points_coords\n",
        "    current_mrmpd_data[\"radial_angles_deg\"] = RADIAL_ANGLES_DEG; print(f\"  MPLD計算完了（全周）。\")\n",
        "\n",
        "    mrd1_mm = mpld_mm_values.get(90.0, np.nan); mrd2_mm = mpld_mm_values.get(270.0, np.nan)\n",
        "    current_mrmpd_data[\"MRD1_mm\"] = mrd1_mm; current_mrmpd_data[\"MRD2_mm\"] = mrd2_mm\n",
        "    print(f\"  MRD-1 (90°): {mrd1_mm:.2f} mm\" if not np.isnan(mrd1_mm) else \"  MRD-1 (90°): N/A\")\n",
        "    print(f\"  MRD-2 (270°): {mrd2_mm:.2f} mm\" if not np.isnan(mrd2_mm) else \"  MRD-2 (270°): N/A\")\n",
        "\n",
        "    img_viz_mrmpd_pil = pil_image_clean_crop.copy().convert(\"RGB\"); draw = ImageDraw.Draw(img_viz_mrmpd_pil)\n",
        "    draw.ellipse((pupil_cx-3, pupil_cy-3, pupil_cx+3, pupil_cy+3), fill=\"red\", outline=\"red\") # 瞳孔中心\n",
        "    for angle_deg in RADIAL_ANGLES_DEG:\n",
        "        int_pt = intersection_points_coords.get(angle_deg); line_color = \"yellow\"\n",
        "        if angle_deg == 90.0 and int_pt: line_color = \"lime\"\n",
        "        if angle_deg == 270.0 and int_pt: line_color = \"green\"\n",
        "        if int_pt:\n",
        "            draw.line([(pupil_cx, pupil_cy), int_pt], fill=line_color, width=2)\n",
        "            draw.ellipse((int_pt[0]-3, int_pt[1]-3, int_pt[0]+3, int_pt[1]+3), fill=\"cyan\", outline=\"cyan\") # 交点\n",
        "        else: # 交点が見つからなかった場合 (デバッグ用に短い線を描画)\n",
        "            angle_rad = math.radians(angle_deg)\n",
        "            end_x_no_int = int(round(pupil_cx + 30 * math.cos(angle_rad))) # 30pxの短い線\n",
        "            end_y_no_int = int(round(pupil_cy - 30 * math.sin(angle_rad)))\n",
        "            draw.line([(pupil_cx, pupil_cy), (end_x_no_int, end_y_no_int)], fill=(128,128,128,180), width=1) # グレーの線\n",
        "    plt.figure(figsize=(8, 8)); plt.imshow(img_viz_mrmpd_pil)\n",
        "    title_str = f\"MRMPD解析結果 - 画像 {debug_img_id_str}\"\n",
        "    if not np.isnan(mrd1_mm): title_str += f\"\\nMRD1: {mrd1_mm:.2f}mm\"\n",
        "    if not np.isnan(mrd2_mm): title_str += f\", MRD2: {mrd2_mm:.2f}mm\"\n",
        "    plt.title(title_str); plt.axis(\"off\"); viz_filename = os.path.join(output_dir, f\"mrmpd_visualization_{debug_img_id_str}.png\")\n",
        "    try: img_viz_mrmpd_pil.save(viz_filename); print(f\"  可視化画像を保存: {viz_filename}\")\n",
        "    except Exception as e: print(f\"  可視化画像保存失敗: {e}\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- 個別極座標プロット (Eyelidマスク輪郭を重ねる) ---\n",
        "    fig_polar, ax_polar = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(7, 7))\n",
        "    contour_plot_theta_rad_for_storage, contour_plot_r_mm_for_storage = [], [] # 保存用\n",
        "    if eyelid_mask_area is not None and pupil_center is not None and pixels_per_mm is not None and pixels_per_mm > 1e-6:\n",
        "        eyelid_contours_for_plot, _ = cv2.findContours(eyelid_mask_area, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if eyelid_contours_for_plot:\n",
        "            largest_eyelid_contour_for_plot = max(eyelid_contours_for_plot, key=cv2.contourArea).reshape(-1,2)\n",
        "            temp_contour_theta_rad, temp_contour_r_mm = [], []\n",
        "            for point_xy in largest_eyelid_contour_for_plot:\n",
        "                x_c, y_c = point_xy; delta_x = x_c - pupil_cx; delta_y = y_c - pupil_cy\n",
        "                r_px = math.sqrt(delta_x**2 + delta_y**2); theta_rad_c = math.atan2(pupil_cy - y_c, x_c - pupil_cx)\n",
        "                temp_contour_r_mm.append(r_px / pixels_per_mm); temp_contour_theta_rad.append(theta_rad_c)\n",
        "\n",
        "            if len(temp_contour_theta_rad) > 1: # 輪郭を閉じる\n",
        "                # 描画用にソートと補間を行うとより滑らかになるが、ここでは単純にプロット\n",
        "                # データを保存用に格納\n",
        "                contour_plot_theta_rad_for_storage = list(temp_contour_theta_rad) # コピーを作成\n",
        "                contour_plot_r_mm_for_storage = list(temp_contour_r_mm)\n",
        "\n",
        "                # 輪郭を閉じるために始点を終点に追加 (保存用にも)\n",
        "                contour_plot_theta_rad_for_storage.append(temp_contour_theta_rad[0])\n",
        "                contour_plot_r_mm_for_storage.append(temp_contour_r_mm[0])\n",
        "\n",
        "                # 描画用にも閉じたデータを使用\n",
        "                plot_theta_contour = list(contour_plot_theta_rad_for_storage)\n",
        "                plot_r_contour = list(contour_plot_r_mm_for_storage)\n",
        "                ax_polar.plot(plot_theta_contour, plot_r_contour, color='lightgray', linestyle='-', linewidth=1.5, zorder=1, label='Eyelid Mask輪郭')\n",
        "\n",
        "    # ★★★ 輪郭データをcurrent_mrmpd_dataに保存 ★★★\n",
        "    current_mrmpd_data[\"eyelid_contour_theta_rad\"] = contour_plot_theta_rad_for_storage\n",
        "    current_mrmpd_data[\"eyelid_contour_r_mm\"] = contour_plot_r_mm_for_storage\n",
        "\n",
        "    mrmpd_plot_angles_rad, mrmpd_plot_radii_mm = [], []\n",
        "    # 凡例用のフラグ\n",
        "    legend_added_angles = set()\n",
        "\n",
        "    for angle_deg_plot in RADIAL_ANGLES_DEG:\n",
        "        val_mm = mpld_mm_values.get(angle_deg_plot, np.nan)\n",
        "        if not np.isnan(val_mm):\n",
        "            rad_angle = math.radians(angle_deg_plot)\n",
        "            mrmpd_plot_angles_rad.append(rad_angle); mrmpd_plot_radii_mm.append(val_mm)\n",
        "            point_color = 'blue'; point_size = 30; label_text = None\n",
        "            if angle_deg_plot == 90.0: point_color = 'lime'; point_size=60; label_text = f'MRD1 ({angle_deg_plot}°)'\n",
        "            elif angle_deg_plot == 270.0: point_color = 'green'; point_size=60; label_text = f'MRD2 ({angle_deg_plot}°)'\n",
        "            elif angle_deg_plot in [0, 45, 135, 180, 225, 315] and angle_deg_plot not in legend_added_angles: # 代表的な角度も表示\n",
        "                 point_color='cornflowerblue'; point_size=40; label_text = f'{angle_deg_plot}°'\n",
        "                 legend_added_angles.add(angle_deg_plot)\n",
        "\n",
        "            ax_polar.scatter(rad_angle, val_mm, color=point_color, s=point_size, zorder=2, label=label_text)\n",
        "\n",
        "    # 凡例の重複を避けるため、一度だけ追加する処理\n",
        "    handles, labels = ax_polar.get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles)) # ラベルでユニークにする\n",
        "    if by_label: # 凡例がある場合のみ\n",
        "        ax_polar.legend(by_label.values(), by_label.keys(), loc='upper right', bbox_to_anchor=(1.35, 1.05))\n",
        "\n",
        "\n",
        "    if mrmpd_plot_radii_mm or contour_plot_r_mm_for_storage: # 何かしらデータがある場合\n",
        "        if eye_side_detected == 'L':\n",
        "            ax_polar.set_theta_zero_location(\"W\"); ax_polar.set_theta_direction(-1)\n",
        "            print(f\"  左眼の個別プロット軸ラベルを調整済。0度が左(鼻側)、180度が右(耳側)。\")\n",
        "            angle_ticks_display = RADIAL_ANGLES_DEG[::3] # 45度ごと\n",
        "            ax_polar.set_xticks(np.deg2rad(angle_ticks_display))\n",
        "            # 左眼の場合、表示されるラベルは物理的な方向を示すようにする\n",
        "            # (例: プロット内部の0度は物理的な180度なので、ラベルは「180°」)\n",
        "            tick_labels_for_L_eye = [f\"{int(normalize_angle_deg(180 - angle))}\\u00b0\" for angle in angle_ticks_display]\n",
        "            ax_polar.set_xticklabels(tick_labels_for_L_eye)\n",
        "        else:\n",
        "            ax_polar.set_theta_zero_location(\"E\"); ax_polar.set_theta_direction(1)\n",
        "            print(f\"  右眼の個別プロット軸。0度が右(鼻側)、180度が左(耳側)。\")\n",
        "            angle_ticks_display = RADIAL_ANGLES_DEG[::3]\n",
        "            ax_polar.set_xticks(np.deg2rad(angle_ticks_display))\n",
        "            ax_polar.set_xticklabels([f\"{int(angle)}\\u00b0\" for angle in angle_ticks_display])\n",
        "\n",
        "        all_r_values_for_plot = [r for r in mrmpd_plot_radii_mm if not np.isnan(r)] + \\\n",
        "                                [r for r in contour_plot_r_mm_for_storage if r is not None and not np.isnan(r)]\n",
        "        if all_r_values_for_plot:\n",
        "            max_r_val = max(all_r_values_for_plot) if all_r_values_for_plot else 5.0\n",
        "            ax_polar.set_rmax(math.ceil(max_r_val * 1.15 if max_r_val > 0 else 5.5))\n",
        "        else:\n",
        "            ax_polar.set_rmax(5.0)\n",
        "\n",
        "        ax_polar.set_title(f\"MPLDとEyelidマスク輪郭 - 画像 {debug_img_id_str}\", va='bottom', pad=25)\n",
        "        polar_plot_filename = os.path.join(output_dir, f\"mrmpd_polar_plot_with_mask_{debug_img_id_str}.png\")\n",
        "        try:\n",
        "            fig_polar.savefig(polar_plot_filename, bbox_inches='tight')\n",
        "            print(f\"  極座標プロット(マスク輪郭付)を保存: {polar_plot_filename}\")\n",
        "        except Exception as e: print(f\"  極座標プロット(マスク輪郭付)保存失敗: {e}\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"  画像 {debug_img_id_str} の極座標プロット用有効MPLD/輪郭データなし。\")\n",
        "        plt.close(fig_polar) # プロットウィンドウを閉じる\n",
        "\n",
        "    asymmetry_ratios_calculated = {}\n",
        "    ratio_angle_pairs = [(105, 75), (120, 60), (135, 45), (150, 30), (165, 15)] # 180/0は自明なので除外も検討\n",
        "    # MRD1/MRDnasal_0deg なども追加可能\n",
        "    print(\"  左右非対称比 (上まぶたのみ, 側頭側 / 鼻側):\")\n",
        "    if angle_inner_end_deg is not None and angle_outer_end_deg is not None:\n",
        "        print(f\"    上まぶた角度範囲(推定): 内端 {angle_inner_end_deg:.1f}°～外端 {angle_outer_end_deg:.1f}° でペア評価\")\n",
        "        for t_angle, n_angle in ratio_angle_pairs:\n",
        "            is_t_in_upper = is_angle_in_upper_lid_range(t_angle, angle_inner_end_deg, angle_outer_end_deg)\n",
        "            is_n_in_upper = is_angle_in_upper_lid_range(n_angle, angle_inner_end_deg, angle_outer_end_deg)\n",
        "            ratio_label = f\"{t_angle}°/{n_angle}°\"\n",
        "            if is_t_in_upper and is_n_in_upper:\n",
        "                temporal_val = mpld_mm_values.get(t_angle, np.nan); nasal_val = mpld_mm_values.get(n_angle, np.nan)\n",
        "                if not np.isnan(temporal_val) and not np.isnan(nasal_val) and nasal_val != 0:\n",
        "                    ratio = temporal_val / nasal_val; asymmetry_ratios_calculated[ratio_label] = ratio; print(f\"    {ratio_label}: {ratio:.2f}\")\n",
        "                else: asymmetry_ratios_calculated[ratio_label] = np.nan; print(f\"    {ratio_label}: N/A (MPLD値不足)\")\n",
        "            else:\n",
        "                asymmetry_ratios_calculated[ratio_label] = np.nan;\n",
        "                # print(f\"    {ratio_label}: N/A (角度ペアが上眼瞼範囲外)\") # 詳細ログが必要な場合\n",
        "    else: print(\"    上まぶた端角度特定不可のため非対称比計算スキップ。\")\n",
        "    current_mrmpd_data[\"asymmetry_ratios\"] = asymmetry_ratios_calculated\n",
        "    current_mrmpd_data[\"status\"] = \"処理完了\"\n",
        "    all_mrmpd_results_data.append(current_mrmpd_data)\n",
        "\n",
        "print(\"\\n--- MPLD解析 全画像処理完了 ---\")\n",
        "\n",
        "# --- 全画像処理後に左右マージ極座標プロットを生成 ---\n",
        "if all_mrmpd_results_data:\n",
        "    generate_merged_polar_plot(all_mrmpd_results_data, output_dir)\n",
        "else:\n",
        "    print(\"解析結果がないため、左右マージ極座標プロットは生成されません。\")"
      ],
      "metadata": {
        "id": "Zm3xzbmK9BQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bezier --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtUS8BCWYqSo",
        "outputId": "1894c5ba-ebd4-411f-ad2d-7ce78a895692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "# Colabで日本語フォントを使用するための準備 (事前にセルで実行推奨)\n",
        "# !pip install japanize-matplotlib\n",
        "import japanize_matplotlib\n",
        "# !pip install bezier scipy\n",
        "import bezier # ベジェ曲線ライブラリ\n",
        "from scipy.optimize import least_squares # 非線形最小二乗法のため\n",
        "from scipy.spatial.distance import cdist # 最近傍点探索のため\n",
        "\n",
        "# --- 1. パス設定 ---\n",
        "# !!!以下のパスはご自身の環境に合わせてください!!!\n",
        "drive_base_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/\"\n",
        "detect_model_path = os.path.join(drive_base_path, \"models/295+cerebhq1-20000_yolo11l.pt\")\n",
        "seg_model_path = os.path.join(drive_base_path, \"models/eyelid_caruncle_yolo11seg_1-139.pt\")\n",
        "obb_model_path = os.path.join(drive_base_path, \"models/yolo11n_obb_1-295_1to139.pt\")\n",
        "image_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_test_images/退行性眼瞼下垂/1065-20150514-73-130021_f6728a8d37efcf237c38e21309bb4ec7535a838429b7448eddfcc2b1fcc17e68.jpg\" # 解析したい画像\n",
        "\n",
        "# --- 定数定義 ---\n",
        "OBB_CLASS_PUPIL = 'Pupil'\n",
        "SEG_CLASS_EYELID = 'Eyelid'\n",
        "NUM_RESAMPLED_POINTS_FOR_BEZIER = 100 # ベジェフィット用の再サンプル点数\n",
        "\n",
        "# --- 出力ディレクトリ作成 ---\n",
        "output_dir = \"/content/eyelid_bezier_analysis_results\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"結果は '{output_dir}' ディレクトリに保存されます。\")\n",
        "\n",
        "# --- ヘルパー関数 (get_obb_data_by_class_name, get_mask_by_class_name, draw_pil_arrow は変更なし) ---\n",
        "def get_obb_data_by_class_name(obb_results_obj, target_class_name, model_obb_names, img_idx_for_debug=\"N/A\"):\n",
        "    if obb_results_obj is None or not hasattr(obb_results_obj, 'obb') or obb_results_obj.obb is None or \\\n",
        "       not hasattr(obb_results_obj.obb, 'cls') or len(obb_results_obj.obb.cls) == 0: return None\n",
        "    target_cls_indices = []\n",
        "    if isinstance(model_obb_names, dict):\n",
        "        for cls_id, name in model_obb_names.items():\n",
        "            if name == target_class_name: target_cls_indices.append(int(cls_id))\n",
        "    elif isinstance(model_obb_names, list):\n",
        "        for cls_id, name in enumerate(model_obb_names):\n",
        "            if name == target_class_name: target_cls_indices.append(cls_id)\n",
        "    else: print(f\"警告 (画像 {img_idx_for_debug}, get_obb_data): model_obb_names の形式が不明: {type(model_obb_names)}\"); return None\n",
        "    if not target_cls_indices: return None\n",
        "    best_obb_data = None; highest_conf = -1.0\n",
        "    if not hasattr(obb_results_obj.obb, 'conf') or not hasattr(obb_results_obj.obb, 'xywhr'): return None\n",
        "    detected_classes = obb_results_obj.obb.cls.cpu().numpy().astype(int)\n",
        "    confidences = obb_results_obj.obb.conf.cpu().numpy(); xywhr_data = obb_results_obj.obb.xywhr.cpu().numpy()\n",
        "    found_instances = 0\n",
        "    for i in range(len(detected_classes)):\n",
        "        if detected_classes[i] in target_cls_indices:\n",
        "            found_instances +=1; current_conf = confidences[i]\n",
        "            if current_conf > highest_conf:\n",
        "                highest_conf = current_conf\n",
        "                best_obb_data = {\"center_x\": xywhr_data[i][0], \"center_y\": xywhr_data[i][1], \"width\": xywhr_data[i][2], \"height\": xywhr_data[i][3], \"angle_rad\": xywhr_data[i][4], \"confidence\": current_conf }\n",
        "    return best_obb_data if found_instances > 0 and best_obb_data is not None else None\n",
        "\n",
        "def get_mask_by_class_name(seg_results_obj, target_class_name, model_seg_names, target_shape_hw, img_idx_for_debug=\"N/A\"):\n",
        "    if seg_results_obj.masks is None: return None\n",
        "    if not hasattr(seg_results_obj.masks, 'data') or seg_results_obj.masks.data is None: return None\n",
        "    if seg_results_obj.boxes is None: return None\n",
        "    target_cls_indices = []\n",
        "    if isinstance(model_seg_names, dict):\n",
        "        for cls_id, name in model_seg_names.items():\n",
        "            if name == target_class_name: target_cls_indices.append(int(cls_id))\n",
        "    elif isinstance(model_seg_names, list):\n",
        "         for cls_id, name in enumerate(model_seg_names):\n",
        "            if name == target_class_name: target_cls_indices.append(cls_id)\n",
        "    else: print(f\"警告 (画像 {img_idx_for_debug}, get_mask): model_seg_names の形式が不明: {type(model_seg_names)}\"); return None\n",
        "    if not target_cls_indices: return None\n",
        "    relevant_masks_data = []\n",
        "    all_detected_cls_indices = seg_results_obj.boxes.cls.cpu().numpy().astype(int)\n",
        "    raw_masks_tensor = seg_results_obj.masks.data\n",
        "    if raw_masks_tensor is None or len(raw_masks_tensor) == 0: return None\n",
        "    num_to_iterate = min(len(all_detected_cls_indices), raw_masks_tensor.shape[0])\n",
        "    if len(all_detected_cls_indices) != raw_masks_tensor.shape[0]: print(f\"警告 (画像 {img_idx_for_debug}, get_mask): ボックス数とマスク数が不一致。短い方({num_to_iterate})で処理。\")\n",
        "    for i in range(num_to_iterate):\n",
        "        current_model_cls_idx = all_detected_cls_indices[i]\n",
        "        if current_model_cls_idx in target_cls_indices:\n",
        "            try:\n",
        "                mask_proto = raw_masks_tensor[i]; mask_proto_tensor = mask_proto.unsqueeze(0).unsqueeze(0)\n",
        "                if mask_proto_tensor.shape[2:] == target_shape_hw: upsampled_mask_tensor = mask_proto_tensor.squeeze()\n",
        "                else: upsampled_mask_tensor = torch.nn.functional.interpolate(mask_proto_tensor, size=target_shape_hw, mode='bilinear', align_corners=False).squeeze()\n",
        "                mask_np = upsampled_mask_tensor.cpu().numpy(); mask_np_binary = (mask_np > 0.5).astype(np.uint8) * 255\n",
        "                contours_mask, _ = cv2.findContours(mask_np_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # 変数名を変更\n",
        "                area = sum(cv2.contourArea(c) for c in contours_mask) if contours_mask else 0\n",
        "                if area > 0: relevant_masks_data.append({'mask': mask_np_binary, 'area': area})\n",
        "            except Exception as e: print(f\"エラー (画像 {img_idx_for_debug}, get_mask): '{target_class_name}' のインスタンス {i} のマスク処理中に例外: {e}\"); continue\n",
        "    if not relevant_masks_data: return None\n",
        "    largest_mask_data = max(relevant_masks_data, key=lambda x: x['area'])\n",
        "    return largest_mask_data['mask']\n",
        "\n",
        "def draw_pil_arrow(draw, start_point, end_point, color, width=1, head_length=10, head_angle_deg=30):\n",
        "    x1, y1 = start_point; x2, y2 = end_point\n",
        "    draw.line([(x1,y1), (x2,y2)], fill=color, width=width)\n",
        "    angle = math.atan2(y2 - y1, x2 - x1)\n",
        "    angle1 = angle + math.radians(head_angle_deg)\n",
        "    x_h1 = x2 - head_length * math.cos(angle1); y_h1 = y2 - head_length * math.sin(angle1)\n",
        "    draw.line([(x2,y2), (int(round(x_h1)), int(round(y_h1)))], fill=color, width=width)\n",
        "    angle2 = angle - math.radians(head_angle_deg)\n",
        "    x_h2 = x2 - head_length * math.cos(angle2); y_h2 = y2 - head_length * math.sin(angle2)\n",
        "    draw.line([(x2,y2), (int(round(x_h2)), int(round(y_h2)))], fill=color, width=width)\n",
        "\n",
        "# --- ★★★ ヘルパー関数: 上眼瞼縁のベジェ曲線解析と描画 (一致度計算方法変更) ★★★ ---\n",
        "def analyze_and_draw_bezier_eyelid_scipy(pil_image_to_draw_on, eyelid_mask_area_np,\n",
        "                                         inner_canthus_coord_est, outer_canthus_coord_est,\n",
        "                                         image_id_str, output_dir_path, current_analysis_data_dict):\n",
        "    print(f\"  (ベジェ曲線 SciPy) 画像 {image_id_str}: 上眼瞼縁のベジェ曲線解析を開始...\")\n",
        "    current_analysis_data_dict[\"bezier_status\"] = \"処理開始\"\n",
        "    img_to_draw_pil = pil_image_to_draw_on.copy().convert(\"RGB\")\n",
        "    draw = ImageDraw.Draw(img_to_draw_pil)\n",
        "\n",
        "    if eyelid_mask_area_np is None:\n",
        "        print(f\"  (ベジェ曲線) 画像 {image_id_str}: Eyelidマスク提供なし。スキップ。\"); current_analysis_data_dict.update({\"bezier_status\": \"Eyelidマスクなし\", \"bezier_error\": \"Mask is None\"}); return img_to_draw_pil\n",
        "    if inner_canthus_coord_est is None or outer_canthus_coord_est is None:\n",
        "        print(f\"  (ベジェ曲線) 画像 {image_id_str}: 内端または外端の座標提供なし。スキップ。\"); current_analysis_data_dict.update({\"bezier_status\": \"端点座標なし\", \"bezier_error\": \"Canthus coords are None\"}); return img_to_draw_pil\n",
        "\n",
        "    contours, _ = cv2.findContours(eyelid_mask_area_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        print(f\"  (ベジェ曲線) 画像 {image_id_str}: Eyelidマスク輪郭なし。スキップ。\"); current_analysis_data_dict.update({\"bezier_status\": \"輪郭なし\", \"bezier_error\": \"No contours in Eyelid mask\"}); return img_to_draw_pil\n",
        "    largest_contour_all_points = max(contours, key=cv2.contourArea).reshape(-1, 2)\n",
        "\n",
        "    if largest_contour_all_points is not None and len(largest_contour_all_points) > 0:\n",
        "        for pt_contour in largest_contour_all_points: draw.point(tuple(pt_contour), fill=(220, 220, 220))\n",
        "\n",
        "    dist_to_inner = cdist(largest_contour_all_points, np.array([inner_canthus_coord_est]))\n",
        "    idx_p0_on_contour = np.argmin(dist_to_inner)\n",
        "    dist_to_outer = cdist(largest_contour_all_points, np.array([outer_canthus_coord_est]))\n",
        "    idx_p3_on_contour = np.argmin(dist_to_outer)\n",
        "\n",
        "    num_contour_points = len(largest_contour_all_points)\n",
        "    path1_points_raw = []; curr = idx_p0_on_contour\n",
        "    while curr != idx_p3_on_contour: path1_points_raw.append(largest_contour_all_points[curr]); curr = (curr + 1) % num_contour_points\n",
        "    path1_points_raw.append(largest_contour_all_points[idx_p3_on_contour])\n",
        "    path2_points_raw = []; curr = idx_p0_on_contour\n",
        "    while curr != idx_p3_on_contour: path2_points_raw.append(largest_contour_all_points[curr]); curr = (curr - 1 + num_contour_points) % num_contour_points\n",
        "    path2_points_raw.append(largest_contour_all_points[idx_p3_on_contour])\n",
        "\n",
        "    upper_eyelid_arc_raw_points_list_tuples = [] # (x,y)タプルのリストとして保持\n",
        "    temp_raw_point_list = []\n",
        "    if path1_points_raw and path2_points_raw:\n",
        "        avg_y_path1 = np.mean(np.array(path1_points_raw)[:, 1]); avg_y_path2 = np.mean(np.array(path2_points_raw)[:, 1])\n",
        "        temp_raw_point_list = path1_points_raw if avg_y_path1 < avg_y_path2 else path2_points_raw\n",
        "    elif path1_points_raw: temp_raw_point_list = path1_points_raw\n",
        "    elif path2_points_raw: temp_raw_point_list = path2_points_raw\n",
        "\n",
        "    # ★★★ 同じX座標でYが小さい点（上側）のみを残すフィルタリング（オプションとして検討）★★★\n",
        "    # ここでは、まず均等サンプリングを優先し、その後にフィルタリングするか、\n",
        "    # あるいは「上側の弧」選択ロジックがこれをある程度カバーしていると期待します。\n",
        "    # 今回は、まず均等サンプリングのロジックを確実にします。\n",
        "    if not temp_raw_point_list or len(temp_raw_point_list) < 2:\n",
        "        errmsg = f\"上眼瞼縁の元輪郭点群が不足({len(temp_raw_point_list)}点)。\"\n",
        "        print(f\"  (ベジェ曲線) 画像 {image_id_str}: {errmsg}スキップ。\"); current_analysis_data_dict.update({\"bezier_status\": \"元点群不足\", \"bezier_error\": errmsg}); return img_to_draw_pil\n",
        "\n",
        "    raw_arc_points_np = np.array(temp_raw_point_list).astype(float)\n",
        "\n",
        "    segment_lengths = np.linalg.norm(np.diff(raw_arc_points_np, axis=0), axis=1)\n",
        "    cumulative_lengths = np.insert(np.cumsum(segment_lengths), 0, 0)\n",
        "    total_arc_length_raw = cumulative_lengths[-1]\n",
        "    if total_arc_length_raw < 1e-6:\n",
        "        errmsg = \"抽出された上眼瞼縁の弧長がほぼ0。\"\n",
        "        print(f\"  (ベジェ曲線) 画像 {image_id_str}: {errmsg}スキップ。\"); current_analysis_data_dict.update({\"bezier_status\": \"元弧長0\", \"bezier_error\": errmsg}); return img_to_draw_pil\n",
        "\n",
        "    X_sample_points_resampled = np.zeros((NUM_RESAMPLED_POINTS_FOR_BEZIER, 2))\n",
        "    target_distances = np.linspace(0, total_arc_length_raw, NUM_RESAMPLED_POINTS_FOR_BEZIER)\n",
        "    current_raw_idx = 0\n",
        "    for i in range(NUM_RESAMPLED_POINTS_FOR_BEZIER):\n",
        "        target_dist = target_distances[i]\n",
        "        while current_raw_idx < len(cumulative_lengths) - 1 and cumulative_lengths[current_raw_idx + 1] < target_dist:\n",
        "            current_raw_idx += 1\n",
        "        if current_raw_idx >= len(cumulative_lengths) - 1: X_sample_points_resampled[i] = raw_arc_points_np[-1]\n",
        "        else:\n",
        "            s_start_len = cumulative_lengths[current_raw_idx]; s_end_len = cumulative_lengths[current_raw_idx + 1]\n",
        "            p_start_seg = raw_arc_points_np[current_raw_idx]; p_end_seg = raw_arc_points_np[current_raw_idx + 1]\n",
        "            seg_len = s_end_len - s_start_len\n",
        "            alpha = (target_dist - s_start_len) / seg_len if seg_len > 1e-6 else 0.0\n",
        "            X_sample_points_resampled[i] = (1.0 - alpha) * p_start_seg + alpha * p_end_seg\n",
        "    X_sample_points_resampled[-1] = raw_arc_points_np[-1] # 念のため終点を合わせる\n",
        "    X_sample_points = X_sample_points_resampled\n",
        "\n",
        "    P0_fixed = X_sample_points[0]; P3_fixed = X_sample_points[-1]\n",
        "    current_analysis_data_dict[\"bezier_resampled_points_count\"] = len(X_sample_points)\n",
        "    if X_sample_points is not None and len(X_sample_points) > 0:\n",
        "        for i in range(X_sample_points.shape[0]):\n",
        "            pt = X_sample_points[i, :]; draw.ellipse((pt[0]-1.5, pt[1]-1.5, pt[0]+1.5, pt[1]+1.5), fill=\"blue\", outline=\"blue\")\n",
        "\n",
        "    diff_X_resampled = np.diff(X_sample_points, axis=0); d_segments_resampled = np.linalg.norm(diff_X_resampled, axis=1)\n",
        "    t_values = np.zeros(len(X_sample_points)); t_values[1:] = np.cumsum(d_segments_resampled)\n",
        "    arc_length_X_sample_resampled_px = t_values[-1]\n",
        "    if arc_length_X_sample_resampled_px < 1e-6:\n",
        "        errmsg = \"均等サンプリング後のサンプル点の弦長合計がほぼ0です。\"\n",
        "        print(f\"  (ベジェ曲線) 画像 {image_id_str}: {errmsg}スキップ。\"); current_analysis_data_dict.update({\"bezier_status\": \"リサンプル後弦長0\", \"bezier_error\": errmsg}); return img_to_draw_pil\n",
        "    t_values = t_values / arc_length_X_sample_resampled_px\n",
        "    current_analysis_data_dict[\"bezier_sample_arc_length_px\"] = arc_length_X_sample_resampled_px\n",
        "\n",
        "    def residual_bezier(p_flat):\n",
        "        P1 = p_flat[:2]; P2 = p_flat[2:]; ctrl_pts = np.asfortranarray([P0_fixed, P1, P2, P3_fixed]).T\n",
        "        curve = bezier.Curve(ctrl_pts, degree=3)\n",
        "        estimated_points = curve.evaluate_multi(t_values).T\n",
        "        return (estimated_points - X_sample_points).ravel()\n",
        "\n",
        "    p1_init = P0_fixed + (P3_fixed - P0_fixed) / 3.0; p2_init = P0_fixed + 2.0 * (P3_fixed - P0_fixed) / 3.0\n",
        "    p_init_guess = np.concatenate([p1_init, p2_init])\n",
        "    fitted_curve = None; P1_opt, P2_opt = None, None\n",
        "    try:\n",
        "        opt_res = least_squares(residual_bezier, p_init_guess, method='lm')\n",
        "        P1_opt, P2_opt = opt_res.x[:2], opt_res.x[2:]\n",
        "        final_control_points = np.asfortranarray([P0_fixed, P1_opt, P2_opt, P3_fixed]).T\n",
        "        fitted_curve = bezier.Curve(final_control_points, degree=3)\n",
        "    except Exception as e:\n",
        "        errmsg = f\"ベジェ曲線フィッティング中にエラー: {e}\"\n",
        "        print(f\"  (ベジェ曲線) 画像 {image_id_str}: {errmsg}スキップ。\"); current_analysis_data_dict.update({\"bezier_status\": \"フィットエラー\", \"bezier_error\": errmsg}); return img_to_draw_pil\n",
        "\n",
        "    # ★★★ 新しい一致度の計算 (X座標基準のY差分) ★★★\n",
        "    y_differences = []\n",
        "    # ベジェ曲線から高密度に点をサンプリング (プロット用とは別に、X座標がソートされるように)\n",
        "    s_eval = np.linspace(0.0, 1.0, 200) # 点数を増やす\n",
        "    bezier_eval_points = fitted_curve.evaluate_multi(s_eval).T # (200, 2) の形状\n",
        "\n",
        "    # X座標でソート (np.interp のため)\n",
        "    sort_indices = np.argsort(bezier_eval_points[:, 0])\n",
        "    bezier_x_sorted = bezier_eval_points[sort_indices, 0]\n",
        "    bezier_y_sorted = bezier_eval_points[sort_indices, 1]\n",
        "\n",
        "    # X座標の重複を除去 (np.interp のため)\n",
        "    unique_x_indices = np.unique(bezier_x_sorted, return_index=True)[1]\n",
        "    bezier_x_unique = bezier_x_sorted[unique_x_indices]\n",
        "    bezier_y_unique = bezier_y_sorted[unique_x_indices]\n",
        "\n",
        "    if len(bezier_x_unique) < 2: # 補間には最低2点が必要\n",
        "        print(\"  (一致度Y差分) ベジェ曲線上のユニークなX座標が2点未満のため、Y差分での一致度計算をスキップ。\")\n",
        "    else:\n",
        "        for i in range(X_sample_points.shape[0]):\n",
        "            xs_orig, ys_orig = X_sample_points[i, :]\n",
        "            try:\n",
        "                # X_sample_points の x 座標に対応するベジェ曲線上の y 座標を補間\n",
        "                yb_at_xs = np.interp(xs_orig, bezier_x_unique, bezier_y_unique)\n",
        "                y_diff = abs(ys_orig - yb_at_xs)\n",
        "                y_differences.append(y_diff)\n",
        "            except Exception as e_interp:\n",
        "                # print(f\"    (一致度Y差分) 点 {i} (xs={xs_orig:.1f}) の補間中にエラー: {e_interp}\")\n",
        "                continue # この点はスキップ\n",
        "\n",
        "    coincidence_percent_y_str = \"N/A\"; rmse_y_px_str = \"N/A (計算不可)\"\n",
        "    current_analysis_data_dict[\"bezier_y_coincidence_percent\"] = np.nan\n",
        "    current_analysis_data_dict[\"bezier_y_rmse_px\"] = np.nan\n",
        "    current_analysis_data_dict[\"bezier_y_mae_px\"] = np.nan\n",
        "\n",
        "    if y_differences:\n",
        "        mae_y_px = np.mean(y_differences)\n",
        "        rmse_y_px = np.sqrt(np.mean(np.square(y_differences)))\n",
        "\n",
        "        # 正規化の基準: X_sample_points の Y座標の範囲 (高さ)\n",
        "        if len(X_sample_points) > 1:\n",
        "            vertical_range_X = np.max(X_sample_points[:,1]) - np.min(X_sample_points[:,1])\n",
        "            if vertical_range_X < 1e-6 : vertical_range_X = img_h # 全体の高さで代替 (稀なケース)\n",
        "        else:\n",
        "            vertical_range_X = img_h # 点が1つしかない場合は画像の高さで代替\n",
        "        if vertical_range_X < 1e-6: vertical_range_X = 1.0 # ゼロ除算回避\n",
        "\n",
        "        # Y方向のRMSEを、Y方向の広がりで正規化 (例: 広がりの半分を大きなズレとみなす)\n",
        "        normalized_rmse_y = rmse_y_px / (vertical_range_X / 2.0) if vertical_range_X > 1e-6 else float('inf')\n",
        "        coincidence_percent_y = max(0.0, (1.0 - normalized_rmse_y)) * 100.0\n",
        "\n",
        "        coincidence_percent_y_str = f\"{coincidence_percent_y:.1f}%\"\n",
        "        rmse_y_px_str = f\"{rmse_y_px:.4f}px\"\n",
        "        print(f\"  (一致度 Y差分) ベジェ曲線との輪郭一致度 (推定): {coincidence_percent_y_str}, RMSE_y: {rmse_y_px_str}\")\n",
        "        current_analysis_data_dict[\"bezier_y_coincidence_percent\"] = coincidence_percent_y\n",
        "        current_analysis_data_dict[\"bezier_y_rmse_px\"] = rmse_y_px\n",
        "        current_analysis_data_dict[\"bezier_y_mae_px\"] = mae_y_px\n",
        "    else:\n",
        "        print(f\"  (一致度 Y差分) Y座標の差分に基づく一致度計算不可。\")\n",
        "    # ★★★ 新しい一致度計算ここまで ★★★\n",
        "\n",
        "\n",
        "    s_vals = np.linspace(0.0, 1.0, 100); bezier_pts_sampled = fitted_curve.evaluate_multi(s_vals)\n",
        "    bezier_pts_draw_int = [(int(round(p[0])), int(round(p[1]))) for p in bezier_pts_sampled.T]\n",
        "    if len(bezier_pts_draw_int) > 1: draw.line(bezier_pts_draw_int, fill=\"magenta\", width=2)\n",
        "    if P1_opt is not None and P2_opt is not None:\n",
        "        P0_draw = tuple(P0_fixed.astype(int)); P1_draw = tuple(P1_opt.astype(int))\n",
        "        P2_draw = tuple(P2_opt.astype(int)); P3_draw = tuple(P3_fixed.astype(int))\n",
        "        arrow_color = (0, 200, 0);\n",
        "        draw_pil_arrow(draw, P0_draw, P1_draw, arrow_color, width=1, head_length=8, head_angle_deg=25)\n",
        "        draw_pil_arrow(draw, P3_draw, P2_draw, arrow_color, width=1, head_length=8, head_angle_deg=25)\n",
        "        for cp_coord in [P0_draw, P1_draw, P2_draw, P3_draw]:\n",
        "            draw.ellipse((cp_coord[0]-3, cp_coord[1]-3, cp_coord[0]+3, cp_coord[1]+3), fill=\"orange\", outline=\"darkorange\")\n",
        "\n",
        "    plt.figure(figsize=(8,8)); plt.imshow(img_to_draw_pil)\n",
        "    # タイトルに新しい一致度を表示\n",
        "    plt.title(f\"上眼瞼縁のBézier曲線フィット - 画像 {image_id_str}\\n一致度(Y差分): {coincidence_percent_y_str} (RMSE_y: {rmse_y_px_str})\")\n",
        "    plt.axis(\"off\"); bezier_filename = os.path.join(output_dir_path, f\"eyelid_bezier_{image_id_str}.png\")\n",
        "    try: img_to_draw_pil.save(bezier_filename); print(f\"  Bézier曲線画像を保存: {bezier_filename}\")\n",
        "    except Exception as e: print(f\"  Bézier曲線画像保存失敗: {e}\")\n",
        "    plt.show()\n",
        "    current_analysis_data_dict[\"bezier_status\"] = \"ベジェ処理完了\"\n",
        "    return img_to_draw_pil\n",
        "\n",
        "\n",
        "# --- メイン処理 ---\n",
        "print(\"--- モデルのロードを開始します ---\")\n",
        "try:\n",
        "    detect_model = YOLO(detect_model_path); print(f\"Detection model loaded. Names: {detect_model.names}\")\n",
        "    seg_model = YOLO(seg_model_path); print(f\"Segmentation model loaded. Names: {seg_model.names}\")\n",
        "    obb_model = YOLO(obb_model_path); print(f\"OBB model loaded. Names: {obb_model.names}\")\n",
        "except Exception as e: print(f\"モデルロードエラー: {e}\"); exit()\n",
        "\n",
        "print(f\"\\n--- 画像 '{image_path}' のロードを開始 ---\")\n",
        "try:\n",
        "    img_pil_original = Image.open(image_path).convert(\"RGB\")\n",
        "    img_cv_original_rgb = np.array(img_pil_original)\n",
        "    original_img_h, original_img_w = img_cv_original_rgb.shape[:2]\n",
        "    print(f\"Image loaded: {original_img_w}x{original_img_h}\")\n",
        "except Exception as e: print(f\"画像ロードエラー: {e}\"); exit()\n",
        "\n",
        "plt.figure(figsize=(8, 8)); plt.imshow(img_pil_original); plt.title(f\"元画像: {os.path.basename(image_path)}\"); plt.axis(\"off\"); plt.show()\n",
        "\n",
        "print(\"\\n--- 物体検出を実行中 (detect_model) ---\")\n",
        "detect_results_list = detect_model(img_pil_original, verbose=False, conf=0.3)\n",
        "if not detect_results_list or len(detect_results_list[0].boxes) == 0: print(\"物体検出なし。終了。\"); exit()\n",
        "detect_result_obj = detect_results_list[0]; print(\"物体検出完了。\")\n",
        "\n",
        "cropped_images_info_list = []\n",
        "boxes_xyxy = detect_result_obj.boxes.xyxy.cpu().numpy(); class_indices = detect_result_obj.boxes.cls.cpu().numpy().astype(int)\n",
        "print(f\"{len(boxes_xyxy)} BBox検出。\")\n",
        "for i in range(len(boxes_xyxy)):\n",
        "    box = boxes_xyxy[i]; x1, y1, x2, y2 = map(int, box)\n",
        "    cls_idx = class_indices[i]; class_name = detect_model.names[cls_idx]\n",
        "    eye_side = \"Unknown\";\n",
        "    if class_name == 'Left_eye': eye_side = \"L\"\n",
        "    elif class_name == 'Right_eye': eye_side = \"R\"\n",
        "    print(f\"\\nBBox {i+1}処理中: Class='{class_name}', Side='{eye_side}'\")\n",
        "    bbox_width = x2 - x1; bbox_height = y2 - y1\n",
        "    if bbox_width <= 0 or bbox_height <= 0: print(f\"  無効BBoxサイズ。スキップ。\"); continue\n",
        "    bbox_center_x = x1 + bbox_width / 2.0; bbox_center_y = y1 + bbox_height / 2.0\n",
        "    new_width = int(round(bbox_width * 1.5)); new_height = new_width\n",
        "    crop_x1 = int(round(bbox_center_x - new_width / 2.0)); crop_y1 = int(round(bbox_center_y - new_height / 2.0))\n",
        "    crop_x2 = crop_x1 + new_width; crop_y2 = crop_y1 + new_height\n",
        "    slice_x1 = max(0, crop_x1); slice_y1 = max(0, crop_y1)\n",
        "    slice_x2 = min(original_img_w, crop_x2); slice_y2 = min(original_img_h, crop_y2)\n",
        "    cropped_part_final = None\n",
        "    if slice_x1 >= slice_x2 or slice_y1 >= slice_y2:\n",
        "        print(f\"  有効な切り取り領域なし。黒画像生成。\"); cropped_part_final = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
        "    else:\n",
        "        img_slice = img_cv_original_rgb[slice_y1:slice_y2, slice_x1:slice_x2]\n",
        "        if img_slice.size == 0: print(f\"  切り出し部分サイズ0。黒画像生成。\"); cropped_part_final = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            pad_left = max(0, -crop_x1); pad_top = max(0, -crop_y1)\n",
        "            pad_right = max(0, crop_x2 - original_img_w); pad_bottom = max(0, crop_y2 - original_img_h)\n",
        "            cropped_part_with_border = cv2.copyMakeBorder(img_slice, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
        "            if cropped_part_with_border.shape[0] != new_height or cropped_part_with_border.shape[1] != new_width:\n",
        "                cropped_part_final = cv2.resize(cropped_part_with_border, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
        "            else: cropped_part_final = cropped_part_with_border\n",
        "    if cropped_part_final is not None:\n",
        "        cropped_image_pil_object = Image.fromarray(cropped_part_final)\n",
        "        cropped_image_pil_object.filename = f\"{os.path.basename(image_path)}_bbox{i+1}_{eye_side}\"\n",
        "        cropped_images_info_list.append({\"image\": cropped_image_pil_object, \"eye_side\": eye_side,\n",
        "                                         \"original_bbox_index\": i, \"source_filename\": os.path.basename(image_path)})\n",
        "        print(f\"  クロップ画像 {i+1} (Side: {eye_side}) 生成完了。Shape: {cropped_part_final.shape[:2]}\")\n",
        "    else: print(f\"  クロップ画像 {i+1} (Side: {eye_side}) 生成失敗。\")\n",
        "print(f\"\\n{len(cropped_images_info_list)} 個のクロップ画像を生成 (左右情報含む)。\")\n",
        "if cropped_images_info_list:\n",
        "    num_cropped = len(cropped_images_info_list)\n",
        "    cols = min(num_cropped, 3); rows = (num_cropped + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 6 * rows), squeeze=False)\n",
        "    axes = axes.ravel()\n",
        "    for i, img_info in enumerate(cropped_images_info_list):\n",
        "        axes[i].imshow(img_info[\"image\"]); axes[i].set_title(f\"Cropped {i+1} (Side: {img_info['eye_side']})\"); axes[i].axis(\"off\")\n",
        "    for j in range(num_cropped, len(axes)): axes[j].axis(\"off\")\n",
        "    plt.tight_layout(); plt.show(); print(f\"{num_cropped} 個のクロップ画像を表示。\")\n",
        "else: print(\"表示するクロップ画像なし。\")\n",
        "\n",
        "# --- 上眼瞼縁のベジェ曲線解析 ---\n",
        "print(\"\\n--- 上眼瞼縁のベジェ曲線解析を開始します ---\")\n",
        "if not cropped_images_info_list: print(\"ベジェ曲線解析対象のクロップ画像なし。終了。\"); exit()\n",
        "\n",
        "all_bezier_analysis_results = []\n",
        "for img_idx, img_info in enumerate(cropped_images_info_list):\n",
        "    pil_image_clean_crop = img_info[\"image\"]; eye_side_detected = img_info[\"eye_side\"]\n",
        "    source_file_basename = os.path.splitext(img_info[\"source_filename\"])[0]\n",
        "    debug_img_id_str = f\"{source_file_basename}_bbox{img_info['original_bbox_index']+1}_{eye_side_detected}\"\n",
        "    print(f\"\\n--- 画像 {debug_img_id_str} のベジェ曲線解析 ---\")\n",
        "    current_bezier_data = {\"image_id\": debug_img_id_str, \"status\": \"処理開始\", \"eye_side\": eye_side_detected}\n",
        "    img_np_rgb = np.array(pil_image_clean_crop.convert(\"RGB\")); img_h, img_w = img_np_rgb.shape[:2]\n",
        "    pupil_center_for_ref, inner_canthus_coords_est, outer_canthus_coords_est, eyelid_mask_for_bezier = None, None, None, None\n",
        "    try:\n",
        "        obb_results_list = obb_model(pil_image_clean_crop, verbose=False, conf=0.25)\n",
        "        if not obb_results_list: raise ValueError(\"OBBモデル結果なし\")\n",
        "        obb_result_obj = obb_results_list[0]\n",
        "        pupil_obb_data = get_obb_data_by_class_name(obb_result_obj, OBB_CLASS_PUPIL, obb_model.names, debug_img_id_str)\n",
        "        if not pupil_obb_data: raise ValueError(f\"'{OBB_CLASS_PUPIL}' OBBなし\")\n",
        "        pupil_center_for_ref = (int(round(pupil_obb_data[\"center_x\"])), int(round(pupil_obb_data[\"center_y\"])))\n",
        "        current_bezier_data[\"pupil_center_ref_px\"] = pupil_center_for_ref\n",
        "    except Exception as e: print(f\"  (ベジェ) 瞳孔中心取得エラー: {e}。スキップ。\"); current_bezier_data.update({\"error\": f\"瞳孔OBBエラー: {e}\", \"status\": \"ベジェOBBエラー\"}); all_bezier_analysis_results.append(current_bezier_data); continue\n",
        "    try:\n",
        "        seg_results_list = seg_model(pil_image_clean_crop, verbose=False, conf=0.25, retina_masks=True)\n",
        "        if not seg_results_list: raise ValueError(\"Segモデル結果なし\")\n",
        "        seg_result_obj = seg_results_list[0]\n",
        "        eyelid_mask_for_bezier = get_mask_by_class_name(seg_result_obj, SEG_CLASS_EYELID, seg_model.names, (img_h, img_w), debug_img_id_str)\n",
        "        if eyelid_mask_for_bezier is None: raise ValueError(f\"'{SEG_CLASS_EYELID}' マスクなし\")\n",
        "    except Exception as e: print(f\"  (ベジェ) Eyelidマスク取得エラー: {e}。スキップ。\"); current_bezier_data.update({\"error\": f\"Eyelidマスクエラー: {e}\", \"status\": \"ベジェSegエラー\"}); all_bezier_analysis_results.append(current_bezier_data); continue\n",
        "    try:\n",
        "        contours, _ = cv2.findContours(eyelid_mask_for_bezier, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if not contours: raise ValueError(\"Eyelid輪郭なし\")\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        pupil_cx_ref, pupil_cy_ref = pupil_center_for_ref\n",
        "        y_tolerance = img_h * 0.20\n",
        "        points_near_pupil_height = [tuple(p[0]) for p_arr in largest_contour for p in [p_arr] if abs(p[0][1] - pupil_cy_ref) <= y_tolerance]\n",
        "        default_inner_canthus = tuple(largest_contour[largest_contour[:,:,0].argmax()][0])\n",
        "        default_outer_canthus = tuple(largest_contour[largest_contour[:,:,0].argmin()][0])\n",
        "        if default_inner_canthus[0] < default_outer_canthus[0]: default_inner_canthus, default_outer_canthus = default_outer_canthus, default_inner_canthus\n",
        "        if len(points_near_pupil_height) < 2 :\n",
        "            print(f\"  警告 (画像 {debug_img_id_str}): 瞳孔水平線近くのEyelid輪郭点不十分。輪郭全体の左右端を使用。\")\n",
        "            inner_canthus_coords_est, outer_canthus_coords_est = default_inner_canthus, default_outer_canthus\n",
        "        else:\n",
        "            right_points = [p for p in points_near_pupil_height if p[0] > pupil_cx_ref]\n",
        "            left_points = [p for p in points_near_pupil_height if p[0] < pupil_cx_ref]\n",
        "            if not right_points or not left_points:\n",
        "                 print(f\"  警告 (画像 {debug_img_id_str}): 瞳孔水平線上で左右両端のEyelid輪郭点なし。輪郭全体の左右端を使用。\")\n",
        "                 inner_canthus_coords_est, outer_canthus_coords_est = default_inner_canthus, default_outer_canthus\n",
        "            else:\n",
        "                inner_canthus_coords_est = max(right_points, key=lambda p: p[0])\n",
        "                outer_canthus_coords_est = min(left_points, key=lambda p: p[0])\n",
        "        current_bezier_data[\"inner_canthus_coords_est\"] = inner_canthus_coords_est\n",
        "        current_bezier_data[\"outer_canthus_coords_est\"] = outer_canthus_coords_est\n",
        "        print(f\"  ベジェ曲線用 端点(推定): 内端 {inner_canthus_coords_est}, 外端 {outer_canthus_coords_est}\")\n",
        "    except Exception as e: print(f\"  (ベジェ) 上まぶたの端の座標特定中にエラー: {e}。スキップ。\"); current_bezier_data.update({\"error\": f\"端点特定エラー: {e}\", \"status\": \"ベジェ端点エラー\"}); all_bezier_analysis_results.append(current_bezier_data); continue\n",
        "\n",
        "    analyze_and_draw_bezier_eyelid_scipy(\n",
        "        pil_image_clean_crop, eyelid_mask_for_bezier,\n",
        "        inner_canthus_coords_est, outer_canthus_coords_est,\n",
        "        debug_img_id_str, output_dir, current_bezier_data\n",
        "    )\n",
        "    all_bezier_analysis_results.append(current_bezier_data)\n",
        "print(\"\\n--- 上眼瞼縁のベジェ曲線解析 全画像処理完了 ---\")\n",
        "print(\"\\n--- ベジェ曲線解析サマリー ---\")\n",
        "for res_idx, res_data in enumerate(all_bezier_analysis_results):\n",
        "    print(f\"画像 {res_data.get('image_id', res_idx)}: ステータス「{res_data.get('bezier_status', 'N/A')}」\")\n",
        "    if \"bezier_y_coincidence_percent\" in res_data and not np.isnan(res_data[\"bezier_y_coincidence_percent\"]): # ★ Y差分ベースの一致度を参照\n",
        "        print(f\"  一致度(Y差分): {res_data['bezier_y_coincidence_percent']:.1f}%, RMSE_y: {res_data.get('bezier_y_rmse_px', 'N/A'):.2f}px, MAE_y: {res_data.get('bezier_y_mae_px', 'N/A'):.2f}px\")\n",
        "    elif \"bezier_coincidence_percent\" in res_data and not np.isnan(res_data[\"bezier_coincidence_percent\"]): # フォールバック（以前のRMSEベース）\n",
        "        print(f\"  一致度(最近傍点): {res_data['bezier_coincidence_percent']:.1f}%, RMSE: {res_data.get('bezier_rmse_px', 'N/A'):.2f}px, MAE: {res_data.get('bezier_mae_px', 'N/A'):.2f}px\")\n",
        "    if \"bezier_error\" in res_data: print(f\"  エラー詳細: {res_data['bezier_error']}\")"
      ],
      "metadata": {
        "id": "MvOjkyFVus-7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}